{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "CUDA available: True\n",
      "CUDA version in PyTorch: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# GPU 사용 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")  # True여야 함\n",
    "\n",
    "# PyTorch에서 사용하는 CUDA 버전 확인\n",
    "print(f\"CUDA version in PyTorch: {torch.version.cuda}\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\isy\\test\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 수: 2008\n",
      "Validation 데이터 수: 502\n",
      "Test 데이터 수: 628\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 이미지 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "])\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "train_dir = '../PCB_imgs/all/resize/train'\n",
    "val_dir = '../PCB_imgs/all/resize/validation'\n",
    "test_dir = '../PCB_imgs/all/resize/test'\n",
    "\n",
    "# ImageFolder로 데이터셋 불러오기\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 파일 경로 및 타겟 추출\n",
    "train_file_paths = [img[0] for img in train_dataset.imgs]\n",
    "train_targets = train_dataset.targets\n",
    "\n",
    "val_file_paths = [img[0] for img in val_dataset.imgs]\n",
    "val_targets = val_dataset.targets\n",
    "\n",
    "test_file_paths = [img[0] for img in test_dataset.imgs]\n",
    "test_targets = test_dataset.targets\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_file_paths, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': val_file_paths, 'targets': val_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_file_paths, 'targets': test_targets})\n",
    "\n",
    "# 확인을 위해 각 데이터셋의 크기 출력\n",
    "print(f\"Train 데이터 수: {len(train_df)}\")\n",
    "print(f\"Validation 데이터 수: {len(validation_df)}\")\n",
    "print(f\"Test 데이터 수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# resize된 데이터셋 로드\n",
    "input_dir = '../PCB_imgs/all/resize/'\n",
    "dataset = datasets.ImageFolder(root=input_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 정의\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 데이터 로더에서 데이터 가져오기\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape)  # 배치의 이미지 텐서 크기 확인\n",
    "    break  # 첫 번째 배치만 확인\n",
    "    # 배치 크기, 채널 수(RGB), 이미지 크기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 커스텀 데이터세트 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, targets, aug=None, preprocess=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.aug = aug\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.file_paths[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        if self.aug is not None:\n",
    "            image = self.aug(image=image)['image']\n",
    "\n",
    "        if self.preprocess is not None:\n",
    "            image = self.preprocess(image)\n",
    "\n",
    "        image = np.transpose(image, (2, 0, 1))  # (H, W, C) -> (C, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 정의\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.view(-1) # torch.Size([batch_size])로 변환\n",
    "            loss = criterion(outputs, labels)  # 손실 계산\n",
    "            running_test_loss += loss.item()\n",
    "            \n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()  # 0.5 기준으로 이진 분류\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            \n",
    "    # 검증 손실과 정확도\n",
    "    test_loss = running_test_loss / len(test_loader)\n",
    "    test_accuracy = correct_test / total_test\n",
    "    return test_loss, test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
