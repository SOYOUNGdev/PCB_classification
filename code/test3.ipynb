{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "CUDA available: True\n",
      "CUDA version in PyTorch: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# GPU 사용 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")  # True여야 함\n",
    "\n",
    "# PyTorch에서 사용하는 CUDA 버전 확인\n",
    "print(f\"CUDA version in PyTorch: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 20\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\sy\\code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터세트 디렉토리 설정\n",
    "original_dir = '../PCB_imgs/all'\n",
    "original_dataset = ImageFolder(root=original_dir, transform=transform)\n",
    "\n",
    "# 데이터세트 DataLoader로 변환\n",
    "original_loader = DataLoader(original_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 데이터 분할\n",
    "file_paths = [img[0] for img in original_dataset.imgs]\n",
    "targets = original_dataset.targets\n",
    "\n",
    "train_images, test_images, train_targets, test_targets = train_test_split(\n",
    "    file_paths, targets, stratify=targets, test_size=0.2, random_state=124\n",
    ")\n",
    "\n",
    "train_images, validation_images, train_targets, validation_targets = train_test_split(\n",
    "    train_images, train_targets, stratify=train_targets, test_size=0.2, random_state=124\n",
    ")\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_images, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': validation_images, 'targets': validation_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_images, 'targets': test_targets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ng: 1178개\n",
      "train_ok: 830개\n",
      "test_ng: 368개\n",
      "test_ok: 260개\n",
      "val_ng: 294개\n",
      "val_ok: 208개\n"
     ]
    }
   ],
   "source": [
    "# 각 클래스의 이미지 수 확인\n",
    "print(f'train_ng: {sum(train_df['targets'] == 0)}개')  # 0이 ng 클래스인 경우\n",
    "print(f'train_ok: {sum(train_df['targets'] == 1)}개')  # 1이 ok 클래스인 경우\n",
    "print(f'test_ng: {sum(test_df['targets'] == 0)}개') \n",
    "print(f'test_ok: {sum(test_df['targets'] == 1)}개') \n",
    "print(f'val_ng: {sum(validation_df['targets'] == 0)}개') \n",
    "print(f'val_ok: {sum(validation_df['targets'] == 1)}개')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터세트 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, targets, aug=None, preprocess=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.aug = aug\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.file_paths[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        if self.aug is not None:\n",
    "            image = self.aug(image=image)['image']\n",
    "\n",
    "        if self.preprocess is not None:\n",
    "            image = self.preprocess(image)\n",
    "\n",
    "        image = np.transpose(image, (2, 0, 1))  # (H, W, C) -> (C, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 증강 정의\n",
    "# aug = A.Compose([\n",
    "#     A.ShiftScaleRotate(p=0.5),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0, p=0.5)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터세트 인스턴스 생성\n",
    "# train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name in ['vgg16', 'inception']:\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name == 'resnet50':\n",
    "            return 2048  # ResNet50의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.dropout(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = CustomModel(model_name='resnet50').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 및 최적화함수 정의\n",
    "criterion = nn.BCELoss()  # 이진 교차 엔트로피 손실\n",
    "optimizer = optim.Adam(model.parameters())  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 정의\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images, targets = images.to(device), targets.to(device).float()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.view(-1), targets)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs.view(-1) > 0.5).float()\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.4380, Val Loss: 0.8580, Val Accuracy: 0.8287\n",
      "Epoch [2/20], Train Loss: 0.3539, Val Loss: 0.3864, Val Accuracy: 0.8685\n",
      "Epoch [3/20], Train Loss: 0.2648, Val Loss: 0.2955, Val Accuracy: 0.8685\n",
      "Epoch [4/20], Train Loss: 0.2265, Val Loss: 0.3252, Val Accuracy: 0.8606\n",
      "Epoch [5/20], Train Loss: 0.1417, Val Loss: 0.5488, Val Accuracy: 0.8745\n",
      "Epoch [6/20], Train Loss: 0.1573, Val Loss: 1.2962, Val Accuracy: 0.8606\n",
      "Epoch [7/20], Train Loss: 0.1906, Val Loss: 0.4317, Val Accuracy: 0.8606\n",
      "Epoch [8/20], Train Loss: 0.1251, Val Loss: 0.3634, Val Accuracy: 0.8785\n",
      "Epoch [9/20], Train Loss: 0.1205, Val Loss: 0.3613, Val Accuracy: 0.8785\n",
      "Epoch [10/20], Train Loss: 0.0650, Val Loss: 0.3533, Val Accuracy: 0.9084\n",
      "Epoch [11/20], Train Loss: 0.0659, Val Loss: 0.4189, Val Accuracy: 0.8924\n",
      "Epoch [12/20], Train Loss: 0.0459, Val Loss: 0.3152, Val Accuracy: 0.9203\n",
      "Epoch [13/20], Train Loss: 0.0428, Val Loss: 0.3079, Val Accuracy: 0.9283\n",
      "Epoch [14/20], Train Loss: 0.0502, Val Loss: 0.3921, Val Accuracy: 0.9223\n",
      "Epoch [15/20], Train Loss: 0.0183, Val Loss: 0.4325, Val Accuracy: 0.9124\n",
      "Epoch [16/20], Train Loss: 0.0667, Val Loss: 0.2986, Val Accuracy: 0.9104\n",
      "Epoch [17/20], Train Loss: 0.0267, Val Loss: 0.3837, Val Accuracy: 0.9104\n",
      "Epoch [18/20], Train Loss: 0.0151, Val Loss: 0.4745, Val Accuracy: 0.9203\n",
      "Epoch [19/20], Train Loss: 0.0251, Val Loss: 0.4126, Val Accuracy: 0.9183\n",
      "Epoch [20/20], Train Loss: 0.0215, Val Loss: 0.5504, Val Accuracy: 0.9024\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{N_EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4210, Test Accuracy: 0.9220\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
