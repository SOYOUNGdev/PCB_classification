{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "CUDA available: True\n",
      "CUDA version in PyTorch: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# GPU 사용 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")  # True여야 함\n",
    "\n",
    "# PyTorch에서 사용하는 CUDA 버전 확인\n",
    "print(f\"CUDA version in PyTorch: {torch.version.cuda}\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\isy\\test\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 수: 2008\n",
      "Validation 데이터 수: 502\n",
      "Test 데이터 수: 628\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 이미지 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "])\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "train_dir = '../PCB_imgs/all/resize/train'\n",
    "val_dir = '../PCB_imgs/all/resize/validation'\n",
    "test_dir = '../PCB_imgs/all/resize/test'\n",
    "\n",
    "# ImageFolder로 데이터셋 불러오기\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 파일 경로 및 타겟 추출\n",
    "train_file_paths = [img[0] for img in train_dataset.imgs]\n",
    "train_targets = train_dataset.targets\n",
    "\n",
    "val_file_paths = [img[0] for img in val_dataset.imgs]\n",
    "val_targets = val_dataset.targets\n",
    "\n",
    "test_file_paths = [img[0] for img in test_dataset.imgs]\n",
    "test_targets = test_dataset.targets\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_file_paths, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': val_file_paths, 'targets': val_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_file_paths, 'targets': test_targets})\n",
    "\n",
    "# 확인을 위해 각 데이터셋의 크기 출력\n",
    "print(f\"Train 데이터 수: {len(train_df)}\")\n",
    "print(f\"Validation 데이터 수: {len(validation_df)}\")\n",
    "print(f\"Test 데이터 수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# resize된 데이터셋 로드\n",
    "input_dir = '../PCB_imgs/all/resize/'\n",
    "dataset = datasets.ImageFolder(root=input_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 정의\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 데이터 로더에서 데이터 가져오기\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape)  # 배치의 이미지 텐서 크기 확인\n",
    "    break  # 첫 번째 배치만 확인\n",
    "    # 배치 크기, 채널 수(RGB), 이미지 크기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 커스텀 데이터세트 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, targets, aug=None, preprocess=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.aug = aug\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.file_paths[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        if self.aug is not None:\n",
    "            image = self.aug(image=image)['image']\n",
    "\n",
    "        if self.preprocess is not None:\n",
    "            image = self.preprocess(image)\n",
    "\n",
    "        image = np.transpose(image, (2, 0, 1))  # (H, W, C) -> (C, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name in 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50, inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.dropout(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # Sigmoid 제거\n",
    "        # x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 정의\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.view(-1) # torch.Size([batch_size])로 변환\n",
    "            loss = criterion(outputs, labels)  # 손실 계산\n",
    "            running_test_loss += loss.item()\n",
    "            \n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()  # 0.5 기준으로 이진 분류\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            \n",
    "    # 검증 손실과 정확도\n",
    "    test_loss = running_test_loss / len(test_loader)\n",
    "    test_accuracy = correct_test / total_test\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inception 모델 구조만 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16()\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50()\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3()\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2()\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 1)\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)  # Sigmoid 제거\n",
    "        return x  # 최종 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sy\\test\\Lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "# 손실 함수 및 최적화함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 교차 엔트로피 손실\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.5306, Train Accuracy: 0.7405, Val Loss: 0.3859, Val Accuracy: 0.8108\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/20], Train Loss: 0.3745, Train Accuracy: 0.8162, Val Loss: 0.3444, Val Accuracy: 0.8486\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/20], Train Loss: 0.3165, Train Accuracy: 0.8566, Val Loss: 0.3924, Val Accuracy: 0.8446\n",
      "Epoch [4/20], Train Loss: 0.3068, Train Accuracy: 0.8710, Val Loss: 0.3811, Val Accuracy: 0.8566\n",
      "Epoch [5/20], Train Loss: 0.2805, Train Accuracy: 0.8790, Val Loss: 0.3162, Val Accuracy: 0.8606\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/20], Train Loss: 0.2436, Train Accuracy: 0.8969, Val Loss: 0.3729, Val Accuracy: 0.8247\n",
      "Epoch [7/20], Train Loss: 0.2156, Train Accuracy: 0.9109, Val Loss: 0.3913, Val Accuracy: 0.8645\n",
      "Epoch [8/20], Train Loss: 0.2102, Train Accuracy: 0.9218, Val Loss: 0.3595, Val Accuracy: 0.8725\n",
      "Epoch [9/20], Train Loss: 0.1957, Train Accuracy: 0.9218, Val Loss: 0.2952, Val Accuracy: 0.8884\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/20], Train Loss: 0.1939, Train Accuracy: 0.9273, Val Loss: 0.3010, Val Accuracy: 0.9084\n",
      "Epoch [11/20], Train Loss: 0.1696, Train Accuracy: 0.9373, Val Loss: 0.2685, Val Accuracy: 0.9124\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/20], Train Loss: 0.1605, Train Accuracy: 0.9358, Val Loss: 0.2825, Val Accuracy: 0.8924\n",
      "Epoch [13/20], Train Loss: 0.1379, Train Accuracy: 0.9457, Val Loss: 0.4139, Val Accuracy: 0.8466\n",
      "Epoch [14/20], Train Loss: 0.0964, Train Accuracy: 0.9626, Val Loss: 0.4368, Val Accuracy: 0.8705\n",
      "Epoch [15/20], Train Loss: 0.1204, Train Accuracy: 0.9552, Val Loss: 0.3081, Val Accuracy: 0.9064\n",
      "Epoch [16/20], Train Loss: 0.1342, Train Accuracy: 0.9502, Val Loss: 0.3549, Val Accuracy: 0.9004\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# 조기 종료 변수를 초기화합니다.\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 모델 훈련\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")\n",
    "        # 모델 저장 코드를 추가할 수 있습니다.\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17 epoch -> 6m 49.3s  \n",
    "1 epoch -> 24s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2606, Test Accuracy: 0.9124\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 epoch에서 조기 종료 발생.  \n",
    "훈련데이터의 손실값은 감소하는 반면 검증 데이터의 손실값은 증감을 반복함. -> 과적합   \n",
    "\n",
    "Imagenet 데이터에 대해 미리 학습된 파라미터 값을 이용하여 훈련 재진행. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inception모델 구조 + ImageNet 데이터에 대해 미리 학습된 파라미터값 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 1)\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)  # Sigmoid 제거\n",
    "        return x  # 최종 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "# 손실 함수 및 최적화함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 교차 엔트로피 손실\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.3435, Train Accuracy: 0.8471, Val Loss: 0.2101, Val Accuracy: 0.9203\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/20], Train Loss: 0.1041, Train Accuracy: 0.9686, Val Loss: 0.1758, Val Accuracy: 0.9442\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/20], Train Loss: 0.0524, Train Accuracy: 0.9846, Val Loss: 0.1694, Val Accuracy: 0.9382\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/20], Train Loss: 0.0374, Train Accuracy: 0.9880, Val Loss: 0.1787, Val Accuracy: 0.9522\n",
      "Epoch [5/20], Train Loss: 0.0590, Train Accuracy: 0.9781, Val Loss: 0.1907, Val Accuracy: 0.9402\n",
      "Epoch [6/20], Train Loss: 0.0342, Train Accuracy: 0.9880, Val Loss: 0.1503, Val Accuracy: 0.9482\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/20], Train Loss: 0.0128, Train Accuracy: 0.9985, Val Loss: 0.1623, Val Accuracy: 0.9562\n",
      "Epoch [8/20], Train Loss: 0.0026, Train Accuracy: 1.0000, Val Loss: 0.1500, Val Accuracy: 0.9701\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/20], Train Loss: 0.0054, Train Accuracy: 0.9980, Val Loss: 0.1707, Val Accuracy: 0.9602\n",
      "Epoch [10/20], Train Loss: 0.0018, Train Accuracy: 1.0000, Val Loss: 0.1545, Val Accuracy: 0.9661\n",
      "Epoch [11/20], Train Loss: 0.0026, Train Accuracy: 0.9990, Val Loss: 0.1581, Val Accuracy: 0.9661\n",
      "Epoch [12/20], Train Loss: 0.0053, Train Accuracy: 0.9980, Val Loss: 0.1638, Val Accuracy: 0.9602\n",
      "Epoch [13/20], Train Loss: 0.0153, Train Accuracy: 0.9965, Val Loss: 0.2187, Val Accuracy: 0.9522\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# 조기 종료 변수를 초기화합니다.\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 모델 훈련\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")\n",
    "        # 모델 저장 코드를 추가할 수 있습니다.\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14 epoch -> 5m 33.2s  \n",
    "1 epoch -> 24s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1733, Test Accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련데이터와 검증데이터의 정확도 모두 상승하긴 하였으나, 여전히 과적합의 양상을 보임.  \n",
    "\n",
    "##### Inception 모델 + ImageNet 파라미터 + 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sy\\test\\Lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "# 손실 함수 및 최적화함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 교차 엔트로피 손실\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.5783, Train Accuracy: 0.6962, Val Loss: 0.4680, Val Accuracy: 0.7789\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/20], Train Loss: 0.4587, Train Accuracy: 0.7789, Val Loss: 0.3982, Val Accuracy: 0.8048\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/20], Train Loss: 0.4265, Train Accuracy: 0.7854, Val Loss: 0.3833, Val Accuracy: 0.8327\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/20], Train Loss: 0.4052, Train Accuracy: 0.8073, Val Loss: 0.3347, Val Accuracy: 0.8466\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/20], Train Loss: 0.4094, Train Accuracy: 0.8108, Val Loss: 0.3469, Val Accuracy: 0.8446\n",
      "Epoch [6/20], Train Loss: 0.3906, Train Accuracy: 0.8078, Val Loss: 0.3360, Val Accuracy: 0.8645\n",
      "Epoch [7/20], Train Loss: 0.4035, Train Accuracy: 0.8187, Val Loss: 0.3207, Val Accuracy: 0.8606\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/20], Train Loss: 0.3785, Train Accuracy: 0.8237, Val Loss: 0.3795, Val Accuracy: 0.8127\n",
      "Epoch [9/20], Train Loss: 0.4028, Train Accuracy: 0.8053, Val Loss: 0.3652, Val Accuracy: 0.8446\n",
      "Epoch [10/20], Train Loss: 0.3549, Train Accuracy: 0.8322, Val Loss: 0.3058, Val Accuracy: 0.8426\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/20], Train Loss: 0.3494, Train Accuracy: 0.8421, Val Loss: 0.3274, Val Accuracy: 0.8506\n",
      "Epoch [12/20], Train Loss: 0.3492, Train Accuracy: 0.8376, Val Loss: 0.3040, Val Accuracy: 0.8645\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/20], Train Loss: 0.3227, Train Accuracy: 0.8511, Val Loss: 0.3325, Val Accuracy: 0.8685\n",
      "Epoch [14/20], Train Loss: 0.3392, Train Accuracy: 0.8501, Val Loss: 0.2885, Val Accuracy: 0.8745\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/20], Train Loss: 0.3181, Train Accuracy: 0.8586, Val Loss: 0.2835, Val Accuracy: 0.8865\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/20], Train Loss: 0.3278, Train Accuracy: 0.8501, Val Loss: 0.3092, Val Accuracy: 0.8785\n",
      "Epoch [17/20], Train Loss: 0.3431, Train Accuracy: 0.8516, Val Loss: 0.3275, Val Accuracy: 0.8486\n",
      "Epoch [18/20], Train Loss: 0.3140, Train Accuracy: 0.8511, Val Loss: 0.2823, Val Accuracy: 0.8785\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/20], Train Loss: 0.3158, Train Accuracy: 0.8601, Val Loss: 0.2571, Val Accuracy: 0.9004\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/20], Train Loss: 0.3079, Train Accuracy: 0.8625, Val Loss: 0.2653, Val Accuracy: 0.8984\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# 조기 종료 변수를 초기화합니다.\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 모델 훈련\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")\n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 epoch -> 8m 49.3s  \n",
    "1 epoch -> 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sy\\test\\Lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_21184\\3232790612.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_best_model.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_best_model.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2466, Test Accuracy: 0.8869\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합은 없지만 모델의 정확도가 0.86정도로 높지않고, 손실값이 0.3정도로 높음.   \n",
    "충분한 학습을 위해 50 epoch로 학습 시간을 늘리고 학습률 스케줄러를 함께 사용해보기.  \n",
    "\n",
    "##### Inception모델 + ImageNet 파라미터 + 증강 (50 epoch + early stopping + 학습률 스케줄러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sy\\test\\Lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "# 손실 함수 및 최적화함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 교차 엔트로피 손실\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.5889, Train Accuracy: 0.6823, Val Loss: 0.4524, Val Accuracy: 0.8008\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.4746, Train Accuracy: 0.7694, Val Loss: 0.4289, Val Accuracy: 0.7908\n",
      "Epoch [3/50], Train Loss: 0.4680, Train Accuracy: 0.7694, Val Loss: 0.5407, Val Accuracy: 0.7869\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.4248, Train Accuracy: 0.7859, Val Loss: 0.4159, Val Accuracy: 0.7888\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.4246, Train Accuracy: 0.7928, Val Loss: 0.3873, Val Accuracy: 0.8227\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.4153, Train Accuracy: 0.7963, Val Loss: 0.3442, Val Accuracy: 0.8486\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.3917, Train Accuracy: 0.8132, Val Loss: 0.3434, Val Accuracy: 0.8606\n",
      "Epoch [8/50], Train Loss: 0.3924, Train Accuracy: 0.8207, Val Loss: 0.3514, Val Accuracy: 0.8506\n",
      "Epoch [9/50], Train Loss: 0.3763, Train Accuracy: 0.8227, Val Loss: 0.3667, Val Accuracy: 0.8386\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.3660, Train Accuracy: 0.8257, Val Loss: 0.3305, Val Accuracy: 0.8367\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.3648, Train Accuracy: 0.8292, Val Loss: 0.3248, Val Accuracy: 0.8466\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/50], Train Loss: 0.3583, Train Accuracy: 0.8342, Val Loss: 0.2991, Val Accuracy: 0.8904\n",
      "Epoch [13/50], Train Loss: 0.3488, Train Accuracy: 0.8436, Val Loss: 0.3249, Val Accuracy: 0.8466\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.3365, Train Accuracy: 0.8421, Val Loss: 0.2961, Val Accuracy: 0.8665\n",
      "Epoch [15/50], Train Loss: 0.3341, Train Accuracy: 0.8506, Val Loss: 0.3456, Val Accuracy: 0.8546\n",
      "Epoch [16/50], Train Loss: 0.3455, Train Accuracy: 0.8362, Val Loss: 0.5902, Val Accuracy: 0.8028\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.3408, Train Accuracy: 0.8436, Val Loss: 0.2747, Val Accuracy: 0.9024\n",
      "Epoch [18/50], Train Loss: 0.2999, Train Accuracy: 0.8576, Val Loss: 0.3630, Val Accuracy: 0.8227\n",
      "Epoch [19/50], Train Loss: 0.3058, Train Accuracy: 0.8596, Val Loss: 0.2822, Val Accuracy: 0.8825\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/50], Train Loss: 0.2904, Train Accuracy: 0.8760, Val Loss: 0.2468, Val Accuracy: 0.9044\n",
      "Epoch [21/50], Train Loss: 0.2935, Train Accuracy: 0.8760, Val Loss: 0.3703, Val Accuracy: 0.8665\n",
      "Epoch [22/50], Train Loss: 0.2943, Train Accuracy: 0.8695, Val Loss: 0.2657, Val Accuracy: 0.8904\n",
      "Epoch [23/50], Train Loss: 0.2762, Train Accuracy: 0.8735, Val Loss: 0.2738, Val Accuracy: 0.8904\n",
      "Epoch [24/50], Train Loss: 0.2725, Train Accuracy: 0.8919, Val Loss: 0.3307, Val Accuracy: 0.8586\n",
      "Validation loss improved, saving model...\n",
      "Epoch [25/50], Train Loss: 0.2520, Train Accuracy: 0.8909, Val Loss: 0.2287, Val Accuracy: 0.9044\n",
      "Epoch [26/50], Train Loss: 0.2485, Train Accuracy: 0.8994, Val Loss: 0.2660, Val Accuracy: 0.8944\n",
      "Epoch [27/50], Train Loss: 0.2350, Train Accuracy: 0.9024, Val Loss: 0.2360, Val Accuracy: 0.9183\n",
      "Epoch [28/50], Train Loss: 0.2338, Train Accuracy: 0.8989, Val Loss: 0.2399, Val Accuracy: 0.9064\n",
      "Epoch [29/50], Train Loss: 0.2298, Train Accuracy: 0.8979, Val Loss: 0.2500, Val Accuracy: 0.9183\n",
      "Epoch [30/50], Train Loss: 0.2059, Train Accuracy: 0.9124, Val Loss: 0.2390, Val Accuracy: 0.9143\n",
      "Validation loss improved, saving model...\n",
      "Epoch [31/50], Train Loss: 0.2056, Train Accuracy: 0.9109, Val Loss: 0.2211, Val Accuracy: 0.9143\n",
      "Epoch [32/50], Train Loss: 0.1979, Train Accuracy: 0.9153, Val Loss: 0.2307, Val Accuracy: 0.9124\n",
      "Epoch [33/50], Train Loss: 0.2026, Train Accuracy: 0.9203, Val Loss: 0.2311, Val Accuracy: 0.9183\n",
      "Validation loss improved, saving model...\n",
      "Epoch [34/50], Train Loss: 0.2029, Train Accuracy: 0.9138, Val Loss: 0.2116, Val Accuracy: 0.9323\n",
      "Epoch [35/50], Train Loss: 0.1971, Train Accuracy: 0.9148, Val Loss: 0.2183, Val Accuracy: 0.9303\n",
      "Epoch [36/50], Train Loss: 0.1998, Train Accuracy: 0.9109, Val Loss: 0.2135, Val Accuracy: 0.9363\n",
      "Epoch [37/50], Train Loss: 0.1916, Train Accuracy: 0.9213, Val Loss: 0.2224, Val Accuracy: 0.9303\n",
      "Validation loss improved, saving model...\n",
      "Epoch [38/50], Train Loss: 0.1783, Train Accuracy: 0.9313, Val Loss: 0.2075, Val Accuracy: 0.9382\n",
      "Epoch [39/50], Train Loss: 0.1812, Train Accuracy: 0.9248, Val Loss: 0.2115, Val Accuracy: 0.9343\n",
      "Epoch [40/50], Train Loss: 0.1878, Train Accuracy: 0.9283, Val Loss: 0.2231, Val Accuracy: 0.9223\n",
      "Epoch [41/50], Train Loss: 0.2006, Train Accuracy: 0.9223, Val Loss: 0.2128, Val Accuracy: 0.9363\n",
      "Validation loss improved, saving model...\n",
      "Epoch [42/50], Train Loss: 0.1746, Train Accuracy: 0.9293, Val Loss: 0.2063, Val Accuracy: 0.9263\n",
      "Validation loss improved, saving model...\n",
      "Epoch [43/50], Train Loss: 0.1826, Train Accuracy: 0.9223, Val Loss: 0.2039, Val Accuracy: 0.9402\n",
      "Validation loss improved, saving model...\n",
      "Epoch [44/50], Train Loss: 0.1554, Train Accuracy: 0.9338, Val Loss: 0.1919, Val Accuracy: 0.9363\n",
      "Epoch [45/50], Train Loss: 0.1717, Train Accuracy: 0.9238, Val Loss: 0.2169, Val Accuracy: 0.9343\n",
      "Validation loss improved, saving model...\n",
      "Epoch [46/50], Train Loss: 0.1676, Train Accuracy: 0.9313, Val Loss: 0.1867, Val Accuracy: 0.9323\n",
      "Epoch [47/50], Train Loss: 0.1635, Train Accuracy: 0.9323, Val Loss: 0.1897, Val Accuracy: 0.9442\n",
      "Epoch [48/50], Train Loss: 0.1642, Train Accuracy: 0.9328, Val Loss: 0.2473, Val Accuracy: 0.9183\n",
      "Epoch [49/50], Train Loss: 0.1679, Train Accuracy: 0.9278, Val Loss: 0.2013, Val Accuracy: 0.9442\n",
      "Epoch [50/50], Train Loss: 0.1537, Train Accuracy: 0.9407, Val Loss: 0.1992, Val Accuracy: 0.9323\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_best_model_02.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 epoch -> 22m 0.9s     \n",
    "1 epoch -> 26s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_21184\\3483221002.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_best_model_02.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_best_model_02.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1846, Test Accuracy: 0.9172\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train: 0.93 / 0.17\n",
    "Val: 0.93 / 0.19  \n",
    "Test: 0.91 / 0.18  \n",
    "-> 과적합없이 0.9정도의 정확도를 보이는 모델이 학습됨.  \n",
    "이전보다 모델의 성능은 올랐지만, 조금 더 올려보기 위해 batch size를 16으로 줄이고, 데이터의 특징을 뽑아 2048 차원을 50차원으로 축소하는 층을 추가해보고자한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 수: 2008\n",
      "Validation 데이터 수: 502\n",
      "Test 데이터 수: 628\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# 이미지 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "])\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "train_dir = '../PCB_imgs/all/resize/train'\n",
    "val_dir = '../PCB_imgs/all/resize/validation'\n",
    "test_dir = '../PCB_imgs/all/resize/test'\n",
    "\n",
    "# ImageFolder로 데이터셋 불러오기\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 파일 경로 및 타겟 추출\n",
    "train_file_paths = [img[0] for img in train_dataset.imgs]\n",
    "train_targets = train_dataset.targets\n",
    "\n",
    "val_file_paths = [img[0] for img in val_dataset.imgs]\n",
    "val_targets = val_dataset.targets\n",
    "\n",
    "test_file_paths = [img[0] for img in test_dataset.imgs]\n",
    "test_targets = test_dataset.targets\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_file_paths, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': val_file_paths, 'targets': val_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_file_paths, 'targets': test_targets})\n",
    "\n",
    "# 확인을 위해 각 데이터셋의 크기 출력\n",
    "print(f\"Train 데이터 수: {len(train_df)}\")\n",
    "print(f\"Validation 데이터 수: {len(validation_df)}\")\n",
    "print(f\"Test 데이터 수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 299, 299])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# resize된 데이터셋 로드\n",
    "input_dir = '../PCB_imgs/all/resize/'\n",
    "dataset = datasets.ImageFolder(root=input_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 정의\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 데이터 로더에서 데이터 가져오기\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape)  # 배치의 이미지 텐서 크기 확인\n",
    "    break  # 첫 번째 배치만 확인\n",
    "    # 배치 크기, 채널 수(RGB), 이미지 크기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inception + ImageNet + 데이터 증강 (batch size 16, 2048 -> 50차원 축소, 50 epoch, early stopping 10, 학습률 스케줄러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "# 손실 함수 및 최적화함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 교차 엔트로피 손실\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.4041, Train Accuracy: 0.8113, Val Loss: 0.2841, Val Accuracy: 0.8904\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.2383, Train Accuracy: 0.9014, Val Loss: 0.1461, Val Accuracy: 0.9502\n",
      "Epoch [3/50], Train Loss: 0.1089, Train Accuracy: 0.9617, Val Loss: 0.1581, Val Accuracy: 0.9442\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.0937, Train Accuracy: 0.9656, Val Loss: 0.1076, Val Accuracy: 0.9721\n",
      "Epoch [5/50], Train Loss: 0.0680, Train Accuracy: 0.9776, Val Loss: 0.1152, Val Accuracy: 0.9721\n",
      "Epoch [6/50], Train Loss: 0.0640, Train Accuracy: 0.9791, Val Loss: 0.1379, Val Accuracy: 0.9681\n",
      "Epoch [7/50], Train Loss: 0.0507, Train Accuracy: 0.9851, Val Loss: 0.1384, Val Accuracy: 0.9741\n",
      "Epoch [8/50], Train Loss: 0.0504, Train Accuracy: 0.9861, Val Loss: 0.1423, Val Accuracy: 0.9781\n",
      "Epoch [9/50], Train Loss: 0.0301, Train Accuracy: 0.9900, Val Loss: 0.1146, Val Accuracy: 0.9801\n",
      "Epoch [10/50], Train Loss: 0.0290, Train Accuracy: 0.9900, Val Loss: 0.1182, Val Accuracy: 0.9781\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.0175, Train Accuracy: 0.9945, Val Loss: 0.1022, Val Accuracy: 0.9861\n",
      "Epoch [12/50], Train Loss: 0.0125, Train Accuracy: 0.9965, Val Loss: 0.1180, Val Accuracy: 0.9841\n",
      "Epoch [13/50], Train Loss: 0.0068, Train Accuracy: 0.9985, Val Loss: 0.1203, Val Accuracy: 0.9880\n",
      "Epoch [14/50], Train Loss: 0.0126, Train Accuracy: 0.9970, Val Loss: 0.1093, Val Accuracy: 0.9880\n",
      "Epoch [15/50], Train Loss: 0.0048, Train Accuracy: 0.9995, Val Loss: 0.1119, Val Accuracy: 0.9880\n",
      "Epoch [16/50], Train Loss: 0.0095, Train Accuracy: 0.9985, Val Loss: 0.1127, Val Accuracy: 0.9861\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.0080, Train Accuracy: 0.9970, Val Loss: 0.0992, Val Accuracy: 0.9841\n",
      "Epoch [18/50], Train Loss: 0.0114, Train Accuracy: 0.9970, Val Loss: 0.1026, Val Accuracy: 0.9861\n",
      "Epoch [19/50], Train Loss: 0.0039, Train Accuracy: 0.9985, Val Loss: 0.1011, Val Accuracy: 0.9880\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/50], Train Loss: 0.0024, Train Accuracy: 0.9995, Val Loss: 0.0952, Val Accuracy: 0.9861\n",
      "Epoch [21/50], Train Loss: 0.0063, Train Accuracy: 0.9975, Val Loss: 0.1034, Val Accuracy: 0.9861\n",
      "Epoch [22/50], Train Loss: 0.0079, Train Accuracy: 0.9965, Val Loss: 0.1028, Val Accuracy: 0.9880\n",
      "Epoch [23/50], Train Loss: 0.0077, Train Accuracy: 0.9980, Val Loss: 0.1041, Val Accuracy: 0.9880\n",
      "Validation loss improved, saving model...\n",
      "Epoch [24/50], Train Loss: 0.0048, Train Accuracy: 0.9980, Val Loss: 0.0931, Val Accuracy: 0.9861\n",
      "Epoch [25/50], Train Loss: 0.0039, Train Accuracy: 0.9990, Val Loss: 0.1179, Val Accuracy: 0.9900\n",
      "Epoch [26/50], Train Loss: 0.0015, Train Accuracy: 0.9995, Val Loss: 0.1112, Val Accuracy: 0.9900\n",
      "Epoch [27/50], Train Loss: 0.0072, Train Accuracy: 0.9985, Val Loss: 0.1168, Val Accuracy: 0.9861\n",
      "Epoch [28/50], Train Loss: 0.0031, Train Accuracy: 0.9985, Val Loss: 0.1420, Val Accuracy: 0.9880\n",
      "Epoch [29/50], Train Loss: 0.0021, Train Accuracy: 0.9990, Val Loss: 0.1223, Val Accuracy: 0.9900\n",
      "Epoch [30/50], Train Loss: 0.0044, Train Accuracy: 0.9980, Val Loss: 0.1205, Val Accuracy: 0.9900\n",
      "Epoch [31/50], Train Loss: 0.0013, Train Accuracy: 0.9995, Val Loss: 0.1227, Val Accuracy: 0.9880\n",
      "Epoch [32/50], Train Loss: 0.0011, Train Accuracy: 0.9995, Val Loss: 0.1199, Val Accuracy: 0.9900\n",
      "Epoch [33/50], Train Loss: 0.0008, Train Accuracy: 1.0000, Val Loss: 0.1212, Val Accuracy: 0.9900\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_best_model_03.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34 epoch -> 15m 16.8s  \n",
    "1 epoch -> 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_21184\\100461600.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_best_model_03.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_best_model_03.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0770, Test Accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련데이터의 손실값은 계속 감소하지만, 검증데이터의 손실값은 10 epoch이후로 거의 감소하지 않음.   \n",
    "또한 훈련 데이터의 정확도가 1.0을 보임.  \n",
    "\n",
    "과적합 양상을 보이므로 Dropout 층 추가해보기.\n",
    "\n",
    "##### Inception + ImageNet + 데이터 증강 (batch size 16, 2048 -> 50차원 축소, Dropout, 20 epoch, early stopping(10 -> 3), 학습률 스케줄러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "# 손실 함수 및 최적화함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 교차 엔트로피 손실\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/20], Train Loss: 0.4611, Train Accuracy: 0.7759, Val Loss: 0.2896, Val Accuracy: 0.8845\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/20], Train Loss: 0.2696, Train Accuracy: 0.8860, Val Loss: 0.1911, Val Accuracy: 0.9263\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/20], Train Loss: 0.1619, Train Accuracy: 0.9323, Val Loss: 0.1366, Val Accuracy: 0.9402\n",
      "Epoch [4/20], Train Loss: 0.1015, Train Accuracy: 0.9636, Val Loss: 0.2186, Val Accuracy: 0.9263\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/20], Train Loss: 0.0944, Train Accuracy: 0.9731, Val Loss: 0.0966, Val Accuracy: 0.9761\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/20], Train Loss: 0.0512, Train Accuracy: 0.9851, Val Loss: 0.0738, Val Accuracy: 0.9781\n",
      "Epoch [7/20], Train Loss: 0.0487, Train Accuracy: 0.9851, Val Loss: 0.1247, Val Accuracy: 0.9781\n",
      "Epoch [8/20], Train Loss: 0.0584, Train Accuracy: 0.9841, Val Loss: 0.1336, Val Accuracy: 0.9701\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_best_model_04.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 epoch -> 5m 23.3s  \n",
    "1 epoch -> 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_21184\\2502014020.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_best_model_04.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_best_model_04.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam 옵티마이저\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0721, Test Accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train: 0.98 / 0.05  \n",
    "Val: 0.98 / 0.07  \n",
    "Test: 0.98 / 0.07  \n",
    "해당 모델이 best 모델임.  \n",
    "8epoch에서 조기 중단 되었지만, 더 이상 학습을 진행하면 과적합이 심해질 것이라 판단하여 중지."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KFold 교차검증으로 과적합 재확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "data_dir = '../PCB_imgs/all/resize/all'  # 모든 이미지를 포함하는 디렉토리\n",
    "\n",
    "# 이미지와 레이블 로드\n",
    "def load_data(data_dir):\n",
    "    file_paths = []\n",
    "    targets = []\n",
    "    for label in os.listdir(data_dir):\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        for img_file in os.listdir(label_dir):\n",
    "            file_paths.append(os.path.join(label_dir, img_file))\n",
    "            targets.append(label)\n",
    "    return pd.DataFrame({'file_paths': file_paths, 'targets': targets})\n",
    "\n",
    "# 전체 데이터셋 로드\n",
    "full_dataset = load_data(data_dir)\n",
    "\n",
    "# 전체 데이터셋에서 Train (80%)과 Validation (20%) 나누기\n",
    "train_df, val_df = train_test_split(full_dataset, test_size=0.2, random_state=124)\n",
    "\n",
    "# Train, Validation 데이터 개수 확인\n",
    "print(f'Train 데이터 수: {len(train_df)}')     \n",
    "print(f'Validation 데이터 수: {len(val_df)}') \n",
    "\n",
    "# k-Fold Cross Validation 설정\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=124)\n",
    "\n",
    "# 성능 저장을 위한 리스트 초기화\n",
    "fold_train_losses = []\n",
    "fold_val_losses = []\n",
    "fold_train_accuracies = []\n",
    "fold_val_accuracies = []\n",
    "\n",
    "# 5번 k-Fold Cross Validation 진행\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n",
    "    print(f'Fold {fold + 1}/{k_folds}')\n",
    "    \n",
    "    # 각 fold에 대해 데이터셋 설정\n",
    "    train_subset = train_df.iloc[train_idx]\n",
    "    validation_subset = train_df.iloc[val_idx]\n",
    "\n",
    "    aug = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "        A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "        A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "        A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "    ])\n",
    "\n",
    "    # 이미지 변환 정의\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "    ])\n",
    "\n",
    "    # 데이터셋 인스턴스 생성\n",
    "    train_dataset = CustomDataset(train_subset['file_paths'].values, train_subset['targets'].values, aug=aug, preprocess=transform)\n",
    "    validation_dataset = CustomDataset(validation_subset['file_paths'].values, validation_subset['targets'].values, preprocess=transform)\n",
    "\n",
    "    # DataLoader 설정\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = CustomModel(model_name='inception').to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # 각 fold에 대해 학습 진행\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for images, targets in train_loader:\n",
    "            images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs.view(-1), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # 정확도 계산\n",
    "            predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "        \n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        fold_train_losses.append(running_loss / len(train_loader))\n",
    "        fold_train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "        fold_val_losses.append(val_loss)\n",
    "        fold_val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # 조기 종료 로직\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0  # 개선 시 카운터 리셋\n",
    "        else:\n",
    "            patience_counter += 1  # 개선 없을 시 카운터 증가\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "    print(f'Fold {fold + 1} completed. Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# 최종 성능 요약\n",
    "print(\"Training completed across all folds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fine tuning  \n",
    "1차 fine tuning(데이터 증강 + base model 파라미터 freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 수: 2008\n",
      "Validation 데이터 수: 502\n",
      "Test 데이터 수: 628\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 이미지 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "])\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "train_dir = '../PCB_imgs/all/resize/train'\n",
    "val_dir = '../PCB_imgs/all/resize/validation'\n",
    "test_dir = '../PCB_imgs/all/resize/test'\n",
    "\n",
    "# ImageFolder로 데이터셋 불러오기\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 파일 경로 및 타겟 추출\n",
    "train_file_paths = [img[0] for img in train_dataset.imgs]\n",
    "train_targets = train_dataset.targets\n",
    "\n",
    "val_file_paths = [img[0] for img in val_dataset.imgs]\n",
    "val_targets = val_dataset.targets\n",
    "\n",
    "test_file_paths = [img[0] for img in test_dataset.imgs]\n",
    "test_targets = test_dataset.targets\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_file_paths, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': val_file_paths, 'targets': val_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_file_paths, 'targets': test_targets})\n",
    "\n",
    "# 확인을 위해 각 데이터셋의 크기 출력\n",
    "print(f\"Train 데이터 수: {len(train_df)}\")\n",
    "print(f\"Validation 데이터 수: {len(validation_df)}\")\n",
    "print(f\"Test 데이터 수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 299, 299])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# resize된 데이터셋 로드\n",
    "input_dir = '../PCB_imgs/all/resize/all/'\n",
    "dataset = datasets.ImageFolder(root=input_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 정의\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 데이터 로더에서 데이터 가져오기\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape)  # 배치의 이미지 텐서 크기 확인\n",
    "    break  # 첫 번째 배치만 확인\n",
    "    # 배치 크기, 채널 수(RGB), 이미지 크기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 커스텀 데이터세트 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, targets, aug=None, preprocess=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.targets = targets\n",
    "        self.aug = aug\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.file_paths[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        if self.aug is not None:\n",
    "            image = self.aug(image=image)['image']\n",
    "\n",
    "        if self.preprocess is not None:\n",
    "            image = self.preprocess(image)\n",
    "\n",
    "        image = np.transpose(image, (2, 0, 1))  # (H, W, C) -> (C, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 새로 추가된 분류기 레이어만 학습\n",
    "optimizer = optim.Adam(model.fc1.parameters(), lr=0.0001) \n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/20], Train Loss: 0.6027, Train Accuracy: 0.7062, Val Loss: 0.5694, Val Accuracy: 0.7351\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/20], Train Loss: 0.5618, Train Accuracy: 0.7455, Val Loss: 0.5383, Val Accuracy: 0.7570\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/20], Train Loss: 0.5431, Train Accuracy: 0.7425, Val Loss: 0.5106, Val Accuracy: 0.7789\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/20], Train Loss: 0.5177, Train Accuracy: 0.7729, Val Loss: 0.4928, Val Accuracy: 0.8048\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/20], Train Loss: 0.5066, Train Accuracy: 0.7620, Val Loss: 0.4785, Val Accuracy: 0.8028\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/20], Train Loss: 0.5005, Train Accuracy: 0.7639, Val Loss: 0.4689, Val Accuracy: 0.7928\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/20], Train Loss: 0.4915, Train Accuracy: 0.7774, Val Loss: 0.4574, Val Accuracy: 0.8108\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/20], Train Loss: 0.4802, Train Accuracy: 0.7749, Val Loss: 0.4525, Val Accuracy: 0.7928\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/20], Train Loss: 0.4808, Train Accuracy: 0.7734, Val Loss: 0.4442, Val Accuracy: 0.8247\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/20], Train Loss: 0.4625, Train Accuracy: 0.7874, Val Loss: 0.4337, Val Accuracy: 0.8247\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/20], Train Loss: 0.4724, Train Accuracy: 0.7774, Val Loss: 0.4319, Val Accuracy: 0.8127\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/20], Train Loss: 0.4522, Train Accuracy: 0.7943, Val Loss: 0.4235, Val Accuracy: 0.8267\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/20], Train Loss: 0.4535, Train Accuracy: 0.7923, Val Loss: 0.4205, Val Accuracy: 0.8287\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/20], Train Loss: 0.4595, Train Accuracy: 0.7908, Val Loss: 0.4188, Val Accuracy: 0.8207\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/20], Train Loss: 0.4402, Train Accuracy: 0.7993, Val Loss: 0.4115, Val Accuracy: 0.8367\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/20], Train Loss: 0.4362, Train Accuracy: 0.8028, Val Loss: 0.4100, Val Accuracy: 0.8327\n",
      "Epoch [17/20], Train Loss: 0.4406, Train Accuracy: 0.7998, Val Loss: 0.4112, Val Accuracy: 0.8147\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/20], Train Loss: 0.4333, Train Accuracy: 0.7938, Val Loss: 0.4029, Val Accuracy: 0.8327\n",
      "Epoch [19/20], Train Loss: 0.4319, Train Accuracy: 0.8118, Val Loss: 0.4040, Val Accuracy: 0.8207\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/20], Train Loss: 0.4362, Train Accuracy: 0.7973, Val Loss: 0.3975, Val Accuracy: 0.8287\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    # scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")\n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_01.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 epoch -> 3m 37.9s  \n",
    "1 epcoh -> 11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_19612\\3990394212.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_01.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_01.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 새로 추가된 분류기 레이어만 학습\n",
    "optimizer = optim.Adam(model.fc1.parameters(), lr=0.0001) \n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3943, Test Accuracy: 0.8312\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1차 fine tuning 결과:  \n",
    "과적합은 없으나 모델의 성능이 높지 않음. -> 더 많은 학습을 위해 epoch를 늘려보기.  \n",
    "추가 30 epoch 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/30], Train Loss: 0.4360, Train Accuracy: 0.8023, Val Loss: 0.3946, Val Accuracy: 0.8386\n",
      "Epoch [2/30], Train Loss: 0.4351, Train Accuracy: 0.7943, Val Loss: 0.3963, Val Accuracy: 0.8187\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/30], Train Loss: 0.4392, Train Accuracy: 0.7948, Val Loss: 0.3878, Val Accuracy: 0.8426\n",
      "Epoch [4/30], Train Loss: 0.4138, Train Accuracy: 0.8063, Val Loss: 0.3901, Val Accuracy: 0.8406\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/30], Train Loss: 0.4408, Train Accuracy: 0.7968, Val Loss: 0.3861, Val Accuracy: 0.8367\n",
      "Epoch [6/30], Train Loss: 0.4214, Train Accuracy: 0.8058, Val Loss: 0.3912, Val Accuracy: 0.8426\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/30], Train Loss: 0.4166, Train Accuracy: 0.8083, Val Loss: 0.3857, Val Accuracy: 0.8426\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/30], Train Loss: 0.4188, Train Accuracy: 0.8078, Val Loss: 0.3851, Val Accuracy: 0.8287\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/30], Train Loss: 0.4315, Train Accuracy: 0.7973, Val Loss: 0.3811, Val Accuracy: 0.8426\n",
      "Epoch [10/30], Train Loss: 0.4238, Train Accuracy: 0.8068, Val Loss: 0.3812, Val Accuracy: 0.8386\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/30], Train Loss: 0.4176, Train Accuracy: 0.8063, Val Loss: 0.3806, Val Accuracy: 0.8466\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/30], Train Loss: 0.4308, Train Accuracy: 0.7928, Val Loss: 0.3789, Val Accuracy: 0.8307\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/30], Train Loss: 0.4225, Train Accuracy: 0.8008, Val Loss: 0.3745, Val Accuracy: 0.8446\n",
      "Epoch [14/30], Train Loss: 0.4195, Train Accuracy: 0.8063, Val Loss: 0.3766, Val Accuracy: 0.8367\n",
      "Epoch [15/30], Train Loss: 0.4179, Train Accuracy: 0.8098, Val Loss: 0.3765, Val Accuracy: 0.8307\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/30], Train Loss: 0.4226, Train Accuracy: 0.8013, Val Loss: 0.3715, Val Accuracy: 0.8386\n",
      "Epoch [17/30], Train Loss: 0.4156, Train Accuracy: 0.8123, Val Loss: 0.3741, Val Accuracy: 0.8386\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/30], Train Loss: 0.4179, Train Accuracy: 0.8132, Val Loss: 0.3714, Val Accuracy: 0.8386\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/30], Train Loss: 0.4128, Train Accuracy: 0.8118, Val Loss: 0.3698, Val Accuracy: 0.8406\n",
      "Epoch [20/30], Train Loss: 0.4211, Train Accuracy: 0.8063, Val Loss: 0.3767, Val Accuracy: 0.8247\n",
      "Validation loss improved, saving model...\n",
      "Epoch [21/30], Train Loss: 0.4173, Train Accuracy: 0.8093, Val Loss: 0.3684, Val Accuracy: 0.8446\n",
      "Validation loss improved, saving model...\n",
      "Epoch [22/30], Train Loss: 0.4150, Train Accuracy: 0.8162, Val Loss: 0.3657, Val Accuracy: 0.8446\n",
      "Epoch [23/30], Train Loss: 0.4114, Train Accuracy: 0.8028, Val Loss: 0.3719, Val Accuracy: 0.8506\n",
      "Epoch [24/30], Train Loss: 0.3932, Train Accuracy: 0.8212, Val Loss: 0.3669, Val Accuracy: 0.8426\n",
      "Epoch [25/30], Train Loss: 0.4054, Train Accuracy: 0.8083, Val Loss: 0.3675, Val Accuracy: 0.8526\n",
      "Validation loss improved, saving model...\n",
      "Epoch [26/30], Train Loss: 0.4163, Train Accuracy: 0.8172, Val Loss: 0.3648, Val Accuracy: 0.8426\n",
      "Epoch [27/30], Train Loss: 0.4078, Train Accuracy: 0.8197, Val Loss: 0.3661, Val Accuracy: 0.8486\n",
      "Epoch [28/30], Train Loss: 0.4186, Train Accuracy: 0.8103, Val Loss: 0.3694, Val Accuracy: 0.8287\n",
      "Validation loss improved, saving model...\n",
      "Epoch [29/30], Train Loss: 0.4078, Train Accuracy: 0.8118, Val Loss: 0.3646, Val Accuracy: 0.8526\n",
      "Epoch [30/30], Train Loss: 0.4111, Train Accuracy: 0.8127, Val Loss: 0.3647, Val Accuracy: 0.8486\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    # scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")\n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_01.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_19612\\3990394212.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_01.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_01.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 새로 추가된 분류기 레이어만 학습\n",
    "optimizer = optim.Adam(model.fc1.parameters(), lr=0.0001) \n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3542, Test Accuracy: 0.8408\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30epoch동안 학습을 추가로 진행하였지만, 훈련 데이터의 손실값이 감소하지 않고 정확도 또한 이전에 비해 0.2정도 소폭 상승했음.  \n",
    "다른 층 미세조정을 시도해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2차 fine tuning(데이터 증강 + Mixed 7c 이후 레이어들 unfreeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: Conv2d_1a_3x3, Layer Type: BasicConv2d(\n",
      "  (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Layer Name: Conv2d_2a_3x3, Layer Type: BasicConv2d(\n",
      "  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Layer Name: Conv2d_2b_3x3, Layer Type: BasicConv2d(\n",
      "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Layer Name: maxpool1, Layer Type: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Layer Name: Conv2d_3b_1x1, Layer Type: BasicConv2d(\n",
      "  (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Layer Name: Conv2d_4a_3x3, Layer Type: BasicConv2d(\n",
      "  (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Layer Name: maxpool2, Layer Type: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Layer Name: Mixed_5b, Layer Type: InceptionA(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch5x5_1): BasicConv2d(\n",
      "    (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch5x5_2): BasicConv2d(\n",
      "    (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_5c, Layer Type: InceptionA(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch5x5_1): BasicConv2d(\n",
      "    (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch5x5_2): BasicConv2d(\n",
      "    (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_5d, Layer Type: InceptionA(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch5x5_1): BasicConv2d(\n",
      "    (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch5x5_2): BasicConv2d(\n",
      "    (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_6a, Layer Type: InceptionB(\n",
      "  (branch3x3): BasicConv2d(\n",
      "    (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_6b, Layer Type: InceptionC(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_2): BasicConv2d(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_3): BasicConv2d(\n",
      "    (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_4): BasicConv2d(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_5): BasicConv2d(\n",
      "    (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_6c, Layer Type: InceptionC(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_2): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_3): BasicConv2d(\n",
      "    (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_4): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_5): BasicConv2d(\n",
      "    (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_6d, Layer Type: InceptionC(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_2): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_3): BasicConv2d(\n",
      "    (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_4): BasicConv2d(\n",
      "    (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_5): BasicConv2d(\n",
      "    (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_6e, Layer Type: InceptionC(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_2): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7_3): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_3): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_4): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7dbl_5): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: AuxLogits, Layer Type: InceptionAux(\n",
      "  (conv0): BasicConv2d(\n",
      "    (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1): BasicConv2d(\n",
      "    (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "Layer Name: Mixed_7a, Layer Type: InceptionD(\n",
      "  (branch3x3_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3_2): BasicConv2d(\n",
      "    (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7x3_1): BasicConv2d(\n",
      "    (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7x3_2): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7x3_3): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch7x7x3_4): BasicConv2d(\n",
      "    (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_7b, Layer Type: InceptionE(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3_1): BasicConv2d(\n",
      "    (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3_2a): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3_2b): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3a): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3b): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: Mixed_7c, Layer Type: InceptionE(\n",
      "  (branch1x1): BasicConv2d(\n",
      "    (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3_1): BasicConv2d(\n",
      "    (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3_2a): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3_2b): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_1): BasicConv2d(\n",
      "    (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_2): BasicConv2d(\n",
      "    (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3a): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch3x3dbl_3b): BasicConv2d(\n",
      "    (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "    (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (branch_pool): BasicConv2d(\n",
      "    (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Layer Name: avgpool, Layer Type: AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Layer Name: dropout, Layer Type: Dropout(p=0.5, inplace=False)\n",
      "Layer Name: fc, Layer Type: Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# ResNet50 사전 학습된 모델 로드\n",
    "model = models.inception_v3(weights='IMAGENET1K_V1')\n",
    "\n",
    "# 모델의 레이어 이름과 타입 확인\n",
    "for name, layer in model.named_children():\n",
    "    print(f\"Layer Name: {name}, Layer Type: {layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: True\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1. 20 epoch + early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/20], Train Loss: 0.6408, Train Accuracy: 0.6454, Val Loss: 0.6005, Val Accuracy: 0.7430\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/20], Train Loss: 0.5970, Train Accuracy: 0.7052, Val Loss: 0.5564, Val Accuracy: 0.7689\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/20], Train Loss: 0.5443, Train Accuracy: 0.7445, Val Loss: 0.5176, Val Accuracy: 0.7849\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/20], Train Loss: 0.5120, Train Accuracy: 0.7605, Val Loss: 0.4839, Val Accuracy: 0.7888\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/20], Train Loss: 0.4841, Train Accuracy: 0.7784, Val Loss: 0.4600, Val Accuracy: 0.7928\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/20], Train Loss: 0.4510, Train Accuracy: 0.7968, Val Loss: 0.4373, Val Accuracy: 0.7988\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/20], Train Loss: 0.4393, Train Accuracy: 0.7948, Val Loss: 0.4199, Val Accuracy: 0.8028\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/20], Train Loss: 0.4227, Train Accuracy: 0.8033, Val Loss: 0.4037, Val Accuracy: 0.8147\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/20], Train Loss: 0.4195, Train Accuracy: 0.8038, Val Loss: 0.3932, Val Accuracy: 0.8207\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/20], Train Loss: 0.4000, Train Accuracy: 0.8093, Val Loss: 0.3772, Val Accuracy: 0.8207\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/20], Train Loss: 0.3809, Train Accuracy: 0.8242, Val Loss: 0.3676, Val Accuracy: 0.8426\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/20], Train Loss: 0.3690, Train Accuracy: 0.8322, Val Loss: 0.3579, Val Accuracy: 0.8327\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/20], Train Loss: 0.3480, Train Accuracy: 0.8411, Val Loss: 0.3485, Val Accuracy: 0.8526\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/20], Train Loss: 0.3518, Train Accuracy: 0.8372, Val Loss: 0.3453, Val Accuracy: 0.8506\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/20], Train Loss: 0.3352, Train Accuracy: 0.8431, Val Loss: 0.3317, Val Accuracy: 0.8606\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/20], Train Loss: 0.3160, Train Accuracy: 0.8576, Val Loss: 0.3231, Val Accuracy: 0.8606\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/20], Train Loss: 0.3378, Train Accuracy: 0.8367, Val Loss: 0.3165, Val Accuracy: 0.8625\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/20], Train Loss: 0.3045, Train Accuracy: 0.8700, Val Loss: 0.3082, Val Accuracy: 0.8685\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/20], Train Loss: 0.2988, Train Accuracy: 0.8665, Val Loss: 0.3038, Val Accuracy: 0.8705\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/20], Train Loss: 0.2892, Train Accuracy: 0.8790, Val Loss: 0.2997, Val Accuracy: 0.8725\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")\n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_02.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 epoch -> 4m 4.4s  \n",
    "1 epoch -> 12s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_19612\\473295518.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_02.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_02.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2711, Test Accuracy: 0.8854\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합 없이 손실값은 계속 줄고, 정확도는 계속 증가함.  \n",
    "훈련시간 50 epoch로 늘리고 학습률 스케줄러 적용하여 훈련 진행.\n",
    "\n",
    "2-2. 50 epoch + e.s + 학습률 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: True\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.6820, Train Accuracy: 0.5558, Val Loss: 0.6357, Val Accuracy: 0.7072\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.6257, Train Accuracy: 0.6798, Val Loss: 0.5894, Val Accuracy: 0.7629\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.5752, Train Accuracy: 0.7326, Val Loss: 0.5463, Val Accuracy: 0.7789\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.5353, Train Accuracy: 0.7540, Val Loss: 0.5099, Val Accuracy: 0.7849\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.5135, Train Accuracy: 0.7580, Val Loss: 0.4787, Val Accuracy: 0.7908\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.4843, Train Accuracy: 0.7739, Val Loss: 0.4542, Val Accuracy: 0.7908\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.4593, Train Accuracy: 0.7864, Val Loss: 0.4318, Val Accuracy: 0.8008\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/50], Train Loss: 0.4365, Train Accuracy: 0.7998, Val Loss: 0.4165, Val Accuracy: 0.8068\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/50], Train Loss: 0.4180, Train Accuracy: 0.8098, Val Loss: 0.4009, Val Accuracy: 0.8167\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.4074, Train Accuracy: 0.8078, Val Loss: 0.3875, Val Accuracy: 0.8187\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.3869, Train Accuracy: 0.8207, Val Loss: 0.3750, Val Accuracy: 0.8386\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/50], Train Loss: 0.3778, Train Accuracy: 0.8162, Val Loss: 0.3657, Val Accuracy: 0.8426\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/50], Train Loss: 0.3623, Train Accuracy: 0.8421, Val Loss: 0.3582, Val Accuracy: 0.8426\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.3508, Train Accuracy: 0.8367, Val Loss: 0.3470, Val Accuracy: 0.8406\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/50], Train Loss: 0.3404, Train Accuracy: 0.8461, Val Loss: 0.3384, Val Accuracy: 0.8566\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/50], Train Loss: 0.3264, Train Accuracy: 0.8581, Val Loss: 0.3298, Val Accuracy: 0.8506\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.3196, Train Accuracy: 0.8611, Val Loss: 0.3191, Val Accuracy: 0.8645\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.3160, Train Accuracy: 0.8690, Val Loss: 0.3136, Val Accuracy: 0.8705\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/50], Train Loss: 0.3049, Train Accuracy: 0.8616, Val Loss: 0.3032, Val Accuracy: 0.8765\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/50], Train Loss: 0.2960, Train Accuracy: 0.8750, Val Loss: 0.3024, Val Accuracy: 0.8765\n",
      "Validation loss improved, saving model...\n",
      "Epoch [21/50], Train Loss: 0.2779, Train Accuracy: 0.8870, Val Loss: 0.2943, Val Accuracy: 0.8825\n",
      "Validation loss improved, saving model...\n",
      "Epoch [22/50], Train Loss: 0.2826, Train Accuracy: 0.8760, Val Loss: 0.2886, Val Accuracy: 0.8884\n",
      "Validation loss improved, saving model...\n",
      "Epoch [23/50], Train Loss: 0.2674, Train Accuracy: 0.8830, Val Loss: 0.2838, Val Accuracy: 0.8924\n",
      "Validation loss improved, saving model...\n",
      "Epoch [24/50], Train Loss: 0.2564, Train Accuracy: 0.8914, Val Loss: 0.2795, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [25/50], Train Loss: 0.2488, Train Accuracy: 0.8894, Val Loss: 0.2744, Val Accuracy: 0.8984\n",
      "Validation loss improved, saving model...\n",
      "Epoch [26/50], Train Loss: 0.2535, Train Accuracy: 0.8929, Val Loss: 0.2689, Val Accuracy: 0.9004\n",
      "Validation loss improved, saving model...\n",
      "Epoch [27/50], Train Loss: 0.2329, Train Accuracy: 0.9119, Val Loss: 0.2667, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [28/50], Train Loss: 0.2359, Train Accuracy: 0.9039, Val Loss: 0.2644, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [29/50], Train Loss: 0.2354, Train Accuracy: 0.9069, Val Loss: 0.2582, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [30/50], Train Loss: 0.2222, Train Accuracy: 0.9158, Val Loss: 0.2556, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [31/50], Train Loss: 0.2204, Train Accuracy: 0.9089, Val Loss: 0.2548, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [32/50], Train Loss: 0.2147, Train Accuracy: 0.9153, Val Loss: 0.2509, Val Accuracy: 0.8924\n",
      "Validation loss improved, saving model...\n",
      "Epoch [33/50], Train Loss: 0.2101, Train Accuracy: 0.9188, Val Loss: 0.2440, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [34/50], Train Loss: 0.1976, Train Accuracy: 0.9258, Val Loss: 0.2403, Val Accuracy: 0.9143\n",
      "Epoch [35/50], Train Loss: 0.1897, Train Accuracy: 0.9333, Val Loss: 0.2496, Val Accuracy: 0.9084\n",
      "Validation loss improved, saving model...\n",
      "Epoch [36/50], Train Loss: 0.1984, Train Accuracy: 0.9233, Val Loss: 0.2364, Val Accuracy: 0.9104\n",
      "Epoch [37/50], Train Loss: 0.1801, Train Accuracy: 0.9348, Val Loss: 0.2407, Val Accuracy: 0.9064\n",
      "Epoch [38/50], Train Loss: 0.1774, Train Accuracy: 0.9328, Val Loss: 0.2387, Val Accuracy: 0.9124\n",
      "Epoch [39/50], Train Loss: 0.1717, Train Accuracy: 0.9318, Val Loss: 0.2366, Val Accuracy: 0.9124\n",
      "Epoch [40/50], Train Loss: 0.1822, Train Accuracy: 0.9313, Val Loss: 0.2366, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [41/50], Train Loss: 0.1832, Train Accuracy: 0.9263, Val Loss: 0.2346, Val Accuracy: 0.9124\n",
      "Epoch [42/50], Train Loss: 0.1783, Train Accuracy: 0.9288, Val Loss: 0.2381, Val Accuracy: 0.9024\n",
      "Epoch [43/50], Train Loss: 0.1709, Train Accuracy: 0.9363, Val Loss: 0.2347, Val Accuracy: 0.9124\n",
      "Validation loss improved, saving model...\n",
      "Epoch [44/50], Train Loss: 0.1707, Train Accuracy: 0.9387, Val Loss: 0.2273, Val Accuracy: 0.9104\n",
      "Epoch [45/50], Train Loss: 0.1623, Train Accuracy: 0.9407, Val Loss: 0.2342, Val Accuracy: 0.9143\n",
      "Epoch [46/50], Train Loss: 0.1648, Train Accuracy: 0.9353, Val Loss: 0.2367, Val Accuracy: 0.9084\n",
      "Epoch [47/50], Train Loss: 0.1558, Train Accuracy: 0.9437, Val Loss: 0.2391, Val Accuracy: 0.9044\n",
      "Epoch [48/50], Train Loss: 0.1629, Train Accuracy: 0.9363, Val Loss: 0.2295, Val Accuracy: 0.9143\n",
      "Epoch [49/50], Train Loss: 0.1604, Train Accuracy: 0.9338, Val Loss: 0.2330, Val Accuracy: 0.9084\n",
      "Epoch [50/50], Train Loss: 0.1531, Train Accuracy: 0.9412, Val Loss: 0.2379, Val Accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_02.2.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_19612\\1122770391.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_02.2.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_02.2.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2042, Test Accuracy: 0.9236\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터세트로 평가\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34 epoch 이후로 손실값과 정확도에 큰 변화가 없음.  \n",
    "batch size를 조정해보기. \n",
    "\n",
    "2-3. 50 epoch + e.s + 학습률 스케줄러 + batch size (32->16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 수: 2008\n",
      "Validation 데이터 수: 502\n",
      "Test 데이터 수: 628\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# 이미지 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "])\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "train_dir = '../PCB_imgs/all/resize/train'\n",
    "val_dir = '../PCB_imgs/all/resize/validation'\n",
    "test_dir = '../PCB_imgs/all/resize/test'\n",
    "\n",
    "# ImageFolder로 데이터셋 불러오기\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 파일 경로 및 타겟 추출\n",
    "train_file_paths = [img[0] for img in train_dataset.imgs]\n",
    "train_targets = train_dataset.targets\n",
    "\n",
    "val_file_paths = [img[0] for img in val_dataset.imgs]\n",
    "val_targets = val_dataset.targets\n",
    "\n",
    "test_file_paths = [img[0] for img in test_dataset.imgs]\n",
    "test_targets = test_dataset.targets\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_file_paths, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': val_file_paths, 'targets': val_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_file_paths, 'targets': test_targets})\n",
    "\n",
    "# 확인을 위해 각 데이터셋의 크기 출력\n",
    "print(f\"Train 데이터 수: {len(train_df)}\")\n",
    "print(f\"Validation 데이터 수: {len(validation_df)}\")\n",
    "print(f\"Test 데이터 수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 299, 299])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# resize된 데이터셋 로드\n",
    "input_dir = '../PCB_imgs/all/resize/all/'\n",
    "dataset = datasets.ImageFolder(root=input_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 정의\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 데이터 로더에서 데이터 가져오기\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape)  # 배치의 이미지 텐서 크기 확인\n",
    "    break  # 첫 번째 배치만 확인\n",
    "    # 배치 크기, 채널 수(RGB), 이미지 크기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: True\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.5817, Train Accuracy: 0.7221, Val Loss: 0.5397, Val Accuracy: 0.7908\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.5259, Train Accuracy: 0.7629, Val Loss: 0.4877, Val Accuracy: 0.7908\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.4764, Train Accuracy: 0.7869, Val Loss: 0.4490, Val Accuracy: 0.8068\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.4376, Train Accuracy: 0.8028, Val Loss: 0.4154, Val Accuracy: 0.8187\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.4074, Train Accuracy: 0.8217, Val Loss: 0.3910, Val Accuracy: 0.8167\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.3839, Train Accuracy: 0.8267, Val Loss: 0.3738, Val Accuracy: 0.8287\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.3575, Train Accuracy: 0.8391, Val Loss: 0.3504, Val Accuracy: 0.8606\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/50], Train Loss: 0.3380, Train Accuracy: 0.8491, Val Loss: 0.3290, Val Accuracy: 0.8725\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/50], Train Loss: 0.3313, Train Accuracy: 0.8516, Val Loss: 0.3226, Val Accuracy: 0.8845\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.2973, Train Accuracy: 0.8715, Val Loss: 0.3081, Val Accuracy: 0.8845\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.2768, Train Accuracy: 0.8860, Val Loss: 0.3032, Val Accuracy: 0.9004\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/50], Train Loss: 0.2624, Train Accuracy: 0.8934, Val Loss: 0.2814, Val Accuracy: 0.9064\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/50], Train Loss: 0.2345, Train Accuracy: 0.9138, Val Loss: 0.2703, Val Accuracy: 0.9064\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.2350, Train Accuracy: 0.9084, Val Loss: 0.2674, Val Accuracy: 0.8984\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/50], Train Loss: 0.2127, Train Accuracy: 0.9208, Val Loss: 0.2609, Val Accuracy: 0.9163\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/50], Train Loss: 0.1967, Train Accuracy: 0.9333, Val Loss: 0.2501, Val Accuracy: 0.9183\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.1780, Train Accuracy: 0.9382, Val Loss: 0.2478, Val Accuracy: 0.9183\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.1754, Train Accuracy: 0.9407, Val Loss: 0.2365, Val Accuracy: 0.9143\n",
      "Epoch [19/50], Train Loss: 0.1535, Train Accuracy: 0.9467, Val Loss: 0.2380, Val Accuracy: 0.9223\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/50], Train Loss: 0.1662, Train Accuracy: 0.9432, Val Loss: 0.2260, Val Accuracy: 0.9363\n",
      "Epoch [21/50], Train Loss: 0.1378, Train Accuracy: 0.9507, Val Loss: 0.2304, Val Accuracy: 0.9303\n",
      "Validation loss improved, saving model...\n",
      "Epoch [22/50], Train Loss: 0.1306, Train Accuracy: 0.9607, Val Loss: 0.2213, Val Accuracy: 0.9223\n",
      "Epoch [23/50], Train Loss: 0.1303, Train Accuracy: 0.9572, Val Loss: 0.2284, Val Accuracy: 0.9183\n",
      "Epoch [24/50], Train Loss: 0.1142, Train Accuracy: 0.9691, Val Loss: 0.2355, Val Accuracy: 0.9104\n",
      "Epoch [25/50], Train Loss: 0.1153, Train Accuracy: 0.9676, Val Loss: 0.2371, Val Accuracy: 0.9223\n",
      "Epoch [26/50], Train Loss: 0.1233, Train Accuracy: 0.9597, Val Loss: 0.2354, Val Accuracy: 0.9203\n",
      "Epoch [27/50], Train Loss: 0.0957, Train Accuracy: 0.9721, Val Loss: 0.2279, Val Accuracy: 0.9104\n",
      "Epoch [28/50], Train Loss: 0.0852, Train Accuracy: 0.9801, Val Loss: 0.2224, Val Accuracy: 0.9183\n",
      "Epoch [29/50], Train Loss: 0.0890, Train Accuracy: 0.9761, Val Loss: 0.2275, Val Accuracy: 0.9263\n",
      "Epoch [30/50], Train Loss: 0.0915, Train Accuracy: 0.9756, Val Loss: 0.2242, Val Accuracy: 0.9243\n",
      "Epoch [31/50], Train Loss: 0.0824, Train Accuracy: 0.9751, Val Loss: 0.2296, Val Accuracy: 0.9223\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_02.3.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_19612\\2374864345.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_02.3.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_02.3.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2174, Test accuracy: 0.9124\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size를 줄이니 훈련 데이터에 과적합 되는 양상을 보임.  \n",
    "훈련데이터의 손실값만 줄고 검증데이터의 손실값은 0.2 이후로 줄지 않음.  \n",
    "\n",
    "2-4. l2 규제 적용 + BN 층 추가 + early stopping patience 10 -> 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.bn1 = nn.BatchNorm1d(50)\n",
    "        # self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 1)  \n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: True\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: bn1.weight | Requires Grad: True\n",
      "Layer: bn1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.7289, Train Accuracy: 0.5378, Val Loss: 0.5612, Val Accuracy: 0.7709\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.5911, Train Accuracy: 0.6813, Val Loss: 0.4928, Val Accuracy: 0.7789\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.5217, Train Accuracy: 0.7400, Val Loss: 0.4522, Val Accuracy: 0.8127\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.4998, Train Accuracy: 0.7535, Val Loss: 0.4309, Val Accuracy: 0.8108\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.4507, Train Accuracy: 0.7963, Val Loss: 0.4018, Val Accuracy: 0.8267\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.4457, Train Accuracy: 0.7923, Val Loss: 0.3882, Val Accuracy: 0.8347\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.4120, Train Accuracy: 0.8078, Val Loss: 0.3859, Val Accuracy: 0.8247\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/50], Train Loss: 0.3845, Train Accuracy: 0.8207, Val Loss: 0.3576, Val Accuracy: 0.8486\n",
      "Epoch [9/50], Train Loss: 0.3846, Train Accuracy: 0.8302, Val Loss: 0.3634, Val Accuracy: 0.8566\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.3533, Train Accuracy: 0.8526, Val Loss: 0.3353, Val Accuracy: 0.8665\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.3512, Train Accuracy: 0.8476, Val Loss: 0.3205, Val Accuracy: 0.8705\n",
      "Epoch [12/50], Train Loss: 0.3136, Train Accuracy: 0.8760, Val Loss: 0.3272, Val Accuracy: 0.8665\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/50], Train Loss: 0.3046, Train Accuracy: 0.8780, Val Loss: 0.3048, Val Accuracy: 0.8825\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.2928, Train Accuracy: 0.8830, Val Loss: 0.2951, Val Accuracy: 0.8924\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/50], Train Loss: 0.2797, Train Accuracy: 0.8959, Val Loss: 0.2844, Val Accuracy: 0.8924\n",
      "Epoch [16/50], Train Loss: 0.2785, Train Accuracy: 0.8929, Val Loss: 0.2895, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.2727, Train Accuracy: 0.8994, Val Loss: 0.2787, Val Accuracy: 0.9064\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.2540, Train Accuracy: 0.9054, Val Loss: 0.2680, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/50], Train Loss: 0.2285, Train Accuracy: 0.9218, Val Loss: 0.2643, Val Accuracy: 0.9044\n",
      "Epoch [20/50], Train Loss: 0.2189, Train Accuracy: 0.9273, Val Loss: 0.2663, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [21/50], Train Loss: 0.2255, Train Accuracy: 0.9253, Val Loss: 0.2485, Val Accuracy: 0.9163\n",
      "Epoch [22/50], Train Loss: 0.2209, Train Accuracy: 0.9308, Val Loss: 0.2557, Val Accuracy: 0.9124\n",
      "Validation loss improved, saving model...\n",
      "Epoch [23/50], Train Loss: 0.1929, Train Accuracy: 0.9417, Val Loss: 0.2479, Val Accuracy: 0.9124\n",
      "Epoch [24/50], Train Loss: 0.1814, Train Accuracy: 0.9487, Val Loss: 0.2523, Val Accuracy: 0.8984\n",
      "Epoch [25/50], Train Loss: 0.1719, Train Accuracy: 0.9492, Val Loss: 0.2519, Val Accuracy: 0.9044\n",
      "Epoch [26/50], Train Loss: 0.1721, Train Accuracy: 0.9512, Val Loss: 0.2557, Val Accuracy: 0.9143\n",
      "Validation loss improved, saving model...\n",
      "Epoch [27/50], Train Loss: 0.1671, Train Accuracy: 0.9517, Val Loss: 0.2473, Val Accuracy: 0.9004\n",
      "Validation loss improved, saving model...\n",
      "Epoch [28/50], Train Loss: 0.1687, Train Accuracy: 0.9542, Val Loss: 0.2318, Val Accuracy: 0.9163\n",
      "Epoch [29/50], Train Loss: 0.1521, Train Accuracy: 0.9607, Val Loss: 0.2419, Val Accuracy: 0.9064\n",
      "Epoch [30/50], Train Loss: 0.1477, Train Accuracy: 0.9617, Val Loss: 0.2493, Val Accuracy: 0.9024\n",
      "Epoch [31/50], Train Loss: 0.1629, Train Accuracy: 0.9507, Val Loss: 0.2452, Val Accuracy: 0.9044\n",
      "Epoch [32/50], Train Loss: 0.1318, Train Accuracy: 0.9676, Val Loss: 0.2444, Val Accuracy: 0.9004\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_02.4.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33 epoch -> 6m 24.0s  \n",
    "1 epoch -> 8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_02.4.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuarcy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여전히 검증 손실이 크게 줄지않음. 현재 미세조정 진행 중인 inception 모델에 batch size를 16으로 두기에는 너무 작은 사이즈 인 것 같음.   \n",
    "batch size 32로 두고 모델의 비선형성을 늘리기 위해 ReLU 활성화 함수를 추가.  \n",
    "\n",
    "2-5. batch size 32 + ReLU + l2 규제 + 증강 + 50 epoch + early stopping(p=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 수: 2008\n",
      "Validation 데이터 수: 502\n",
      "Test 데이터 수: 628\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 이미지 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "])\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "train_dir = '../PCB_imgs/all/resize/train'\n",
    "val_dir = '../PCB_imgs/all/resize/validation'\n",
    "test_dir = '../PCB_imgs/all/resize/test'\n",
    "\n",
    "# ImageFolder로 데이터셋 불러오기\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 파일 경로 및 타겟 추출\n",
    "train_file_paths = [img[0] for img in train_dataset.imgs]\n",
    "train_targets = train_dataset.targets\n",
    "\n",
    "val_file_paths = [img[0] for img in val_dataset.imgs]\n",
    "val_targets = val_dataset.targets\n",
    "\n",
    "test_file_paths = [img[0] for img in test_dataset.imgs]\n",
    "test_targets = test_dataset.targets\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_file_paths, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': val_file_paths, 'targets': val_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_file_paths, 'targets': test_targets})\n",
    "\n",
    "# 확인을 위해 각 데이터셋의 크기 출력\n",
    "print(f\"Train 데이터 수: {len(train_df)}\")\n",
    "print(f\"Validation 데이터 수: {len(validation_df)}\")\n",
    "print(f\"Test 데이터 수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 299, 299])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# resize된 데이터셋 로드\n",
    "input_dir = '../PCB_imgs/all/resize/all/'\n",
    "dataset = datasets.ImageFolder(root=input_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 정의\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 데이터 로더에서 데이터 가져오기\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape)  # 배치의 이미지 텐서 크기 확인\n",
    "    break  # 첫 번째 배치만 확인\n",
    "    # 배치 크기, 채널 수(RGB), 이미지 크기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 1)  \n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: True\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.6915, Train Accuracy: 0.5294, Val Loss: 0.6657, Val Accuracy: 0.6912\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.6566, Train Accuracy: 0.6375, Val Loss: 0.6354, Val Accuracy: 0.7291\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.6285, Train Accuracy: 0.6982, Val Loss: 0.6012, Val Accuracy: 0.7351\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.5860, Train Accuracy: 0.7351, Val Loss: 0.5599, Val Accuracy: 0.7629\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.5483, Train Accuracy: 0.7754, Val Loss: 0.5185, Val Accuracy: 0.7769\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.5134, Train Accuracy: 0.7824, Val Loss: 0.4821, Val Accuracy: 0.7968\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.4726, Train Accuracy: 0.7913, Val Loss: 0.4561, Val Accuracy: 0.7888\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/50], Train Loss: 0.4452, Train Accuracy: 0.8033, Val Loss: 0.4296, Val Accuracy: 0.8008\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/50], Train Loss: 0.4197, Train Accuracy: 0.8123, Val Loss: 0.4073, Val Accuracy: 0.8147\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.3957, Train Accuracy: 0.8147, Val Loss: 0.3874, Val Accuracy: 0.8227\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.3732, Train Accuracy: 0.8431, Val Loss: 0.3698, Val Accuracy: 0.8327\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/50], Train Loss: 0.3535, Train Accuracy: 0.8521, Val Loss: 0.3505, Val Accuracy: 0.8506\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/50], Train Loss: 0.3387, Train Accuracy: 0.8561, Val Loss: 0.3329, Val Accuracy: 0.8606\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.3098, Train Accuracy: 0.8740, Val Loss: 0.3187, Val Accuracy: 0.8665\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/50], Train Loss: 0.2963, Train Accuracy: 0.8775, Val Loss: 0.3055, Val Accuracy: 0.8765\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/50], Train Loss: 0.2703, Train Accuracy: 0.9069, Val Loss: 0.2921, Val Accuracy: 0.8805\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.2625, Train Accuracy: 0.9094, Val Loss: 0.2796, Val Accuracy: 0.9004\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.2407, Train Accuracy: 0.9188, Val Loss: 0.2744, Val Accuracy: 0.8964\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/50], Train Loss: 0.2322, Train Accuracy: 0.9143, Val Loss: 0.2643, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/50], Train Loss: 0.2254, Train Accuracy: 0.9248, Val Loss: 0.2528, Val Accuracy: 0.9064\n",
      "Validation loss improved, saving model...\n",
      "Epoch [21/50], Train Loss: 0.1979, Train Accuracy: 0.9382, Val Loss: 0.2467, Val Accuracy: 0.9143\n",
      "Validation loss improved, saving model...\n",
      "Epoch [22/50], Train Loss: 0.1737, Train Accuracy: 0.9467, Val Loss: 0.2397, Val Accuracy: 0.9203\n",
      "Validation loss improved, saving model...\n",
      "Epoch [23/50], Train Loss: 0.1618, Train Accuracy: 0.9547, Val Loss: 0.2359, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [24/50], Train Loss: 0.1603, Train Accuracy: 0.9502, Val Loss: 0.2272, Val Accuracy: 0.9223\n",
      "Epoch [25/50], Train Loss: 0.1348, Train Accuracy: 0.9656, Val Loss: 0.2290, Val Accuracy: 0.9163\n",
      "Validation loss improved, saving model...\n",
      "Epoch [26/50], Train Loss: 0.1294, Train Accuracy: 0.9671, Val Loss: 0.2208, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [27/50], Train Loss: 0.1222, Train Accuracy: 0.9681, Val Loss: 0.2177, Val Accuracy: 0.9163\n",
      "Epoch [28/50], Train Loss: 0.1239, Train Accuracy: 0.9636, Val Loss: 0.2222, Val Accuracy: 0.9163\n",
      "Epoch [29/50], Train Loss: 0.1094, Train Accuracy: 0.9716, Val Loss: 0.2195, Val Accuracy: 0.9223\n",
      "Validation loss improved, saving model...\n",
      "Epoch [30/50], Train Loss: 0.0996, Train Accuracy: 0.9776, Val Loss: 0.2168, Val Accuracy: 0.9183\n",
      "Validation loss improved, saving model...\n",
      "Epoch [31/50], Train Loss: 0.0871, Train Accuracy: 0.9811, Val Loss: 0.2133, Val Accuracy: 0.9283\n",
      "Validation loss improved, saving model...\n",
      "Epoch [32/50], Train Loss: 0.0886, Train Accuracy: 0.9811, Val Loss: 0.2115, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [33/50], Train Loss: 0.0788, Train Accuracy: 0.9856, Val Loss: 0.2080, Val Accuracy: 0.9303\n",
      "Epoch [34/50], Train Loss: 0.0720, Train Accuracy: 0.9866, Val Loss: 0.2117, Val Accuracy: 0.9263\n",
      "Epoch [35/50], Train Loss: 0.0621, Train Accuracy: 0.9871, Val Loss: 0.2122, Val Accuracy: 0.9243\n",
      "Epoch [36/50], Train Loss: 0.0573, Train Accuracy: 0.9920, Val Loss: 0.2081, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [37/50], Train Loss: 0.0581, Train Accuracy: 0.9885, Val Loss: 0.2076, Val Accuracy: 0.9283\n",
      "Epoch [38/50], Train Loss: 0.0574, Train Accuracy: 0.9910, Val Loss: 0.2085, Val Accuracy: 0.9223\n",
      "Epoch [39/50], Train Loss: 0.0612, Train Accuracy: 0.9856, Val Loss: 0.2087, Val Accuracy: 0.9183\n",
      "Validation loss improved, saving model...\n",
      "Epoch [40/50], Train Loss: 0.0527, Train Accuracy: 0.9885, Val Loss: 0.2076, Val Accuracy: 0.9243\n",
      "Epoch [41/50], Train Loss: 0.0418, Train Accuracy: 0.9930, Val Loss: 0.2127, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [42/50], Train Loss: 0.0411, Train Accuracy: 0.9930, Val Loss: 0.2059, Val Accuracy: 0.9243\n",
      "Epoch [43/50], Train Loss: 0.0422, Train Accuracy: 0.9925, Val Loss: 0.2087, Val Accuracy: 0.9243\n",
      "Epoch [44/50], Train Loss: 0.0428, Train Accuracy: 0.9930, Val Loss: 0.2149, Val Accuracy: 0.9283\n",
      "Epoch [45/50], Train Loss: 0.0403, Train Accuracy: 0.9935, Val Loss: 0.2151, Val Accuracy: 0.9163\n",
      "Epoch [46/50], Train Loss: 0.0415, Train Accuracy: 0.9940, Val Loss: 0.2185, Val Accuracy: 0.9223\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_02.5.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47 epoch -> 8m 59.0s  \n",
    "1 epoch -> s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_19612\\1221547655.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_02.5.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_02.5.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2138, Test accuarcy: 0.9220\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuarcy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금 더 많은 층 unfreeze (Mixed 7b이후)  \n",
    "3차 fine tuning(데이터 증강 + Mixed 7b 이후 레이어들 unfreeze)  \n",
    "50 epoch + 증강 + 학습률 스케줄러 + early stopping + l2 규제(1e-4) + dropout(0.5 -> 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        # self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 1)  \n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.fc2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: True\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7b 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.base_model.Mixed_7b.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.6387, Train Accuracy: 0.6290, Val Loss: 0.5652, Val Accuracy: 0.7649\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.5518, Train Accuracy: 0.7261, Val Loss: 0.4943, Val Accuracy: 0.7869\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.4850, Train Accuracy: 0.7754, Val Loss: 0.4517, Val Accuracy: 0.7908\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.4426, Train Accuracy: 0.7908, Val Loss: 0.4167, Val Accuracy: 0.7968\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.4250, Train Accuracy: 0.7968, Val Loss: 0.3941, Val Accuracy: 0.8187\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.3899, Train Accuracy: 0.8192, Val Loss: 0.3710, Val Accuracy: 0.8227\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.3625, Train Accuracy: 0.8376, Val Loss: 0.3483, Val Accuracy: 0.8506\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/50], Train Loss: 0.3498, Train Accuracy: 0.8406, Val Loss: 0.3310, Val Accuracy: 0.8566\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/50], Train Loss: 0.3271, Train Accuracy: 0.8501, Val Loss: 0.3176, Val Accuracy: 0.8665\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.2939, Train Accuracy: 0.8745, Val Loss: 0.2999, Val Accuracy: 0.8665\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.2782, Train Accuracy: 0.8805, Val Loss: 0.2891, Val Accuracy: 0.8785\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/50], Train Loss: 0.2525, Train Accuracy: 0.8979, Val Loss: 0.2743, Val Accuracy: 0.8904\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/50], Train Loss: 0.2369, Train Accuracy: 0.9089, Val Loss: 0.2673, Val Accuracy: 0.8964\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.2256, Train Accuracy: 0.9099, Val Loss: 0.2567, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/50], Train Loss: 0.2135, Train Accuracy: 0.9218, Val Loss: 0.2488, Val Accuracy: 0.8964\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/50], Train Loss: 0.1995, Train Accuracy: 0.9223, Val Loss: 0.2424, Val Accuracy: 0.9124\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.1890, Train Accuracy: 0.9338, Val Loss: 0.2359, Val Accuracy: 0.9084\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.1802, Train Accuracy: 0.9328, Val Loss: 0.2286, Val Accuracy: 0.9064\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/50], Train Loss: 0.1657, Train Accuracy: 0.9432, Val Loss: 0.2219, Val Accuracy: 0.9143\n",
      "Epoch [20/50], Train Loss: 0.1634, Train Accuracy: 0.9427, Val Loss: 0.2234, Val Accuracy: 0.9124\n",
      "Validation loss improved, saving model...\n",
      "Epoch [21/50], Train Loss: 0.1483, Train Accuracy: 0.9507, Val Loss: 0.2171, Val Accuracy: 0.9143\n",
      "Epoch [22/50], Train Loss: 0.1423, Train Accuracy: 0.9537, Val Loss: 0.2197, Val Accuracy: 0.9124\n",
      "Validation loss improved, saving model...\n",
      "Epoch [23/50], Train Loss: 0.1452, Train Accuracy: 0.9467, Val Loss: 0.2121, Val Accuracy: 0.9163\n",
      "Validation loss improved, saving model...\n",
      "Epoch [24/50], Train Loss: 0.1383, Train Accuracy: 0.9537, Val Loss: 0.2077, Val Accuracy: 0.9223\n",
      "Epoch [25/50], Train Loss: 0.1225, Train Accuracy: 0.9617, Val Loss: 0.2094, Val Accuracy: 0.9203\n",
      "Epoch [26/50], Train Loss: 0.1224, Train Accuracy: 0.9646, Val Loss: 0.2077, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [27/50], Train Loss: 0.1203, Train Accuracy: 0.9582, Val Loss: 0.2029, Val Accuracy: 0.9203\n",
      "Validation loss improved, saving model...\n",
      "Epoch [28/50], Train Loss: 0.1039, Train Accuracy: 0.9696, Val Loss: 0.2006, Val Accuracy: 0.9263\n",
      "Epoch [29/50], Train Loss: 0.1005, Train Accuracy: 0.9651, Val Loss: 0.2066, Val Accuracy: 0.9243\n",
      "Epoch [30/50], Train Loss: 0.1149, Train Accuracy: 0.9607, Val Loss: 0.2025, Val Accuracy: 0.9323\n",
      "Validation loss improved, saving model...\n",
      "Epoch [31/50], Train Loss: 0.0975, Train Accuracy: 0.9686, Val Loss: 0.1938, Val Accuracy: 0.9363\n",
      "Epoch [32/50], Train Loss: 0.1002, Train Accuracy: 0.9701, Val Loss: 0.1971, Val Accuracy: 0.9263\n",
      "Epoch [33/50], Train Loss: 0.1000, Train Accuracy: 0.9602, Val Loss: 0.2040, Val Accuracy: 0.9223\n",
      "Validation loss improved, saving model...\n",
      "Epoch [34/50], Train Loss: 0.0801, Train Accuracy: 0.9776, Val Loss: 0.1922, Val Accuracy: 0.9323\n",
      "Epoch [35/50], Train Loss: 0.0861, Train Accuracy: 0.9736, Val Loss: 0.1987, Val Accuracy: 0.9303\n",
      "Epoch [36/50], Train Loss: 0.0791, Train Accuracy: 0.9751, Val Loss: 0.1988, Val Accuracy: 0.9303\n",
      "Epoch [37/50], Train Loss: 0.0786, Train Accuracy: 0.9801, Val Loss: 0.2015, Val Accuracy: 0.9263\n",
      "Epoch [38/50], Train Loss: 0.0779, Train Accuracy: 0.9776, Val Loss: 0.1987, Val Accuracy: 0.9303\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_03.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch -> m s  \n",
    "1 epoch -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_19612\\4048364925.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_03.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_03.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 몇 개의 레이어를 동결 해제 (Mixed_7c 이후의 레이어들)\n",
    "for param in model.base_model.Mixed_7c.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.base_model.Mixed_7b.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1663, Test accuarcy: 0.9379\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuarcy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4차 fine tuning (BN 층만 freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 수: 2008\n",
      "Validation 데이터 수: 502\n",
      "Test 데이터 수: 628\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# 이미지 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환 (0~255 범위를 0~1 범위로 정규화)\n",
    "])\n",
    "\n",
    "# 데이터셋 디렉토리 설정\n",
    "train_dir = '../PCB_imgs/all/resize/train'\n",
    "val_dir = '../PCB_imgs/all/resize/validation'\n",
    "test_dir = '../PCB_imgs/all/resize/test'\n",
    "\n",
    "# ImageFolder로 데이터셋 불러오기\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 파일 경로 및 타겟 추출\n",
    "train_file_paths = [img[0] for img in train_dataset.imgs]\n",
    "train_targets = train_dataset.targets\n",
    "\n",
    "val_file_paths = [img[0] for img in val_dataset.imgs]\n",
    "val_targets = val_dataset.targets\n",
    "\n",
    "test_file_paths = [img[0] for img in test_dataset.imgs]\n",
    "test_targets = test_dataset.targets\n",
    "\n",
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame({'file_paths': train_file_paths, 'targets': train_targets})\n",
    "validation_df = pd.DataFrame({'file_paths': val_file_paths, 'targets': val_targets})\n",
    "test_df = pd.DataFrame({'file_paths': test_file_paths, 'targets': test_targets})\n",
    "\n",
    "# 확인을 위해 각 데이터셋의 크기 출력\n",
    "print(f\"Train 데이터 수: {len(train_df)}\")\n",
    "print(f\"Validation 데이터 수: {len(validation_df)}\")\n",
    "print(f\"Test 데이터 수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.5),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.5),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.5933, Train Accuracy: 0.7236, Val Loss: 0.5436, Val Accuracy: 0.7809\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.5175, Train Accuracy: 0.7704, Val Loss: 0.4835, Val Accuracy: 0.7849\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.4635, Train Accuracy: 0.7893, Val Loss: 0.4254, Val Accuracy: 0.8127\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.4100, Train Accuracy: 0.8142, Val Loss: 0.3785, Val Accuracy: 0.8466\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.3785, Train Accuracy: 0.8297, Val Loss: 0.3502, Val Accuracy: 0.8566\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.3326, Train Accuracy: 0.8566, Val Loss: 0.3212, Val Accuracy: 0.8645\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.2873, Train Accuracy: 0.9009, Val Loss: 0.2877, Val Accuracy: 0.8805\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/50], Train Loss: 0.2609, Train Accuracy: 0.9049, Val Loss: 0.2506, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/50], Train Loss: 0.2179, Train Accuracy: 0.9288, Val Loss: 0.2403, Val Accuracy: 0.9004\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.1932, Train Accuracy: 0.9422, Val Loss: 0.2017, Val Accuracy: 0.9143\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.1689, Train Accuracy: 0.9452, Val Loss: 0.1844, Val Accuracy: 0.9323\n",
      "Epoch [12/50], Train Loss: 0.1412, Train Accuracy: 0.9587, Val Loss: 0.1967, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/50], Train Loss: 0.1275, Train Accuracy: 0.9661, Val Loss: 0.1697, Val Accuracy: 0.9363\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.1138, Train Accuracy: 0.9681, Val Loss: 0.1580, Val Accuracy: 0.9482\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/50], Train Loss: 0.1080, Train Accuracy: 0.9701, Val Loss: 0.1480, Val Accuracy: 0.9502\n",
      "Epoch [16/50], Train Loss: 0.0887, Train Accuracy: 0.9741, Val Loss: 0.1557, Val Accuracy: 0.9422\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/50], Train Loss: 0.0874, Train Accuracy: 0.9766, Val Loss: 0.1357, Val Accuracy: 0.9582\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.0668, Train Accuracy: 0.9836, Val Loss: 0.1334, Val Accuracy: 0.9562\n",
      "Epoch [19/50], Train Loss: 0.0630, Train Accuracy: 0.9861, Val Loss: 0.1464, Val Accuracy: 0.9542\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/50], Train Loss: 0.0714, Train Accuracy: 0.9816, Val Loss: 0.1313, Val Accuracy: 0.9542\n",
      "Validation loss improved, saving model...\n",
      "Epoch [21/50], Train Loss: 0.0618, Train Accuracy: 0.9806, Val Loss: 0.1286, Val Accuracy: 0.9602\n",
      "Epoch [22/50], Train Loss: 0.0450, Train Accuracy: 0.9895, Val Loss: 0.1321, Val Accuracy: 0.9562\n",
      "Epoch [23/50], Train Loss: 0.0479, Train Accuracy: 0.9885, Val Loss: 0.1314, Val Accuracy: 0.9542\n",
      "Epoch [24/50], Train Loss: 0.0570, Train Accuracy: 0.9821, Val Loss: 0.1376, Val Accuracy: 0.9542\n",
      "Epoch [25/50], Train Loss: 0.0415, Train Accuracy: 0.9895, Val Loss: 0.1434, Val Accuracy: 0.9562\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_04.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_6604\\4073719916.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_04.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_04.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1410, Test accuracy: 0.9443\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 비해 훈련 검증 손실값이 많이 낮아지고 (0.12), 검증 정확도가 많이 증가(0.96)하였으나  \n",
    "여전히 훈련 손실과 정확도에 비해 낮음.  \n",
    "\n",
    "일반화를 위해 데이터 증강 비율을 늘려보고, 초기 학습률을 1e-5 -> 1e-4로 조정해보기.  \n",
    "4-2. Inception + 증강(0.6) + BN 층 unfreeze + l2규제(le-4) + lr(1e-4) + 학습률 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.6),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.6),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.6),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.6),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(train_df['file_paths'].values, train_df['targets'].values, aug=aug)\n",
    "validation_dataset = CustomDataset(validation_df['file_paths'].values, validation_df['targets'].values)\n",
    "test_dataset = CustomDataset(test_df['file_paths'].values, test_df['targets'].values)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.4616, Train Accuracy: 0.7849, Val Loss: 0.3073, Val Accuracy: 0.8765\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.2617, Train Accuracy: 0.8855, Val Loss: 0.2578, Val Accuracy: 0.8944\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.1989, Train Accuracy: 0.9188, Val Loss: 0.1763, Val Accuracy: 0.9363\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.1336, Train Accuracy: 0.9562, Val Loss: 0.1207, Val Accuracy: 0.9502\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.0819, Train Accuracy: 0.9726, Val Loss: 0.1187, Val Accuracy: 0.9622\n",
      "Epoch [6/50], Train Loss: 0.0755, Train Accuracy: 0.9756, Val Loss: 0.1515, Val Accuracy: 0.9641\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.0512, Train Accuracy: 0.9846, Val Loss: 0.1018, Val Accuracy: 0.9761\n",
      "Epoch [8/50], Train Loss: 0.0346, Train Accuracy: 0.9890, Val Loss: 0.1139, Val Accuracy: 0.9681\n",
      "Epoch [9/50], Train Loss: 0.0320, Train Accuracy: 0.9910, Val Loss: 0.1137, Val Accuracy: 0.9681\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.0183, Train Accuracy: 0.9940, Val Loss: 0.0949, Val Accuracy: 0.9761\n",
      "Epoch [11/50], Train Loss: 0.0342, Train Accuracy: 0.9900, Val Loss: 0.1164, Val Accuracy: 0.9761\n",
      "Epoch [12/50], Train Loss: 0.0308, Train Accuracy: 0.9905, Val Loss: 0.1343, Val Accuracy: 0.9721\n",
      "Epoch [13/50], Train Loss: 0.0314, Train Accuracy: 0.9880, Val Loss: 0.1190, Val Accuracy: 0.9821\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.0170, Train Accuracy: 0.9945, Val Loss: 0.0946, Val Accuracy: 0.9681\n",
      "Epoch [15/50], Train Loss: 0.0152, Train Accuracy: 0.9935, Val Loss: 0.1332, Val Accuracy: 0.9641\n",
      "Epoch [16/50], Train Loss: 0.0335, Train Accuracy: 0.9880, Val Loss: 0.1047, Val Accuracy: 0.9681\n",
      "Epoch [17/50], Train Loss: 0.0174, Train Accuracy: 0.9950, Val Loss: 0.1107, Val Accuracy: 0.9781\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.0140, Train Accuracy: 0.9955, Val Loss: 0.0869, Val Accuracy: 0.9781\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/50], Train Loss: 0.0242, Train Accuracy: 0.9945, Val Loss: 0.0728, Val Accuracy: 0.9841\n",
      "Epoch [20/50], Train Loss: 0.0210, Train Accuracy: 0.9930, Val Loss: 0.1187, Val Accuracy: 0.9781\n",
      "Epoch [21/50], Train Loss: 0.0170, Train Accuracy: 0.9945, Val Loss: 0.0892, Val Accuracy: 0.9861\n",
      "Epoch [22/50], Train Loss: 0.0170, Train Accuracy: 0.9950, Val Loss: 0.0992, Val Accuracy: 0.9861\n",
      "Epoch [23/50], Train Loss: 0.0110, Train Accuracy: 0.9970, Val Loss: 0.0856, Val Accuracy: 0.9781\n",
      "Validation loss improved, saving model...\n",
      "Epoch [24/50], Train Loss: 0.0122, Train Accuracy: 0.9970, Val Loss: 0.0726, Val Accuracy: 0.9841\n",
      "Validation loss improved, saving model...\n",
      "Epoch [25/50], Train Loss: 0.0039, Train Accuracy: 0.9990, Val Loss: 0.0709, Val Accuracy: 0.9861\n",
      "Epoch [26/50], Train Loss: 0.0056, Train Accuracy: 0.9985, Val Loss: 0.0736, Val Accuracy: 0.9880\n",
      "Validation loss improved, saving model...\n",
      "Epoch [27/50], Train Loss: 0.0033, Train Accuracy: 0.9995, Val Loss: 0.0632, Val Accuracy: 0.9880\n",
      "Epoch [28/50], Train Loss: 0.0020, Train Accuracy: 0.9995, Val Loss: 0.0642, Val Accuracy: 0.9920\n",
      "Epoch [29/50], Train Loss: 0.0183, Train Accuracy: 0.9950, Val Loss: 0.0742, Val Accuracy: 0.9841\n",
      "Validation loss improved, saving model...\n",
      "Epoch [30/50], Train Loss: 0.0029, Train Accuracy: 0.9995, Val Loss: 0.0616, Val Accuracy: 0.9920\n",
      "Epoch [31/50], Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 0.0662, Val Accuracy: 0.9920\n",
      "Epoch [32/50], Train Loss: 0.0025, Train Accuracy: 0.9995, Val Loss: 0.0710, Val Accuracy: 0.9900\n",
      "Epoch [33/50], Train Loss: 0.0018, Train Accuracy: 0.9995, Val Loss: 0.0729, Val Accuracy: 0.9880\n",
      "Epoch [34/50], Train Loss: 0.0012, Train Accuracy: 0.9995, Val Loss: 0.0731, Val Accuracy: 0.9861\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_04.2.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35 epoch -> 15m 40.5s  \n",
    "1 epoch -> 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_16664\\357413530.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_04.2.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_04.2.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0471, Test accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련데이터 정확도가 1.0, 0.9995로 상당히 높음. 검증 및 테스트 데이터의 손실값도 0.06, 0.04로 낮은것을 확인.  \n",
    "과적합 정도가 심하지는 않지만, 조금 더 일반화 시키기 위해 BN 층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.bn1 = nn.BatchNorm1d(50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: bn1.weight | Requires Grad: True\n",
      "Layer: bn1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.4825, Train Accuracy: 0.7535, Val Loss: 0.3416, Val Accuracy: 0.8546\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.3081, Train Accuracy: 0.8735, Val Loss: 0.2544, Val Accuracy: 0.9044\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.2431, Train Accuracy: 0.9138, Val Loss: 0.2417, Val Accuracy: 0.9163\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.1986, Train Accuracy: 0.9278, Val Loss: 0.1787, Val Accuracy: 0.9283\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.1557, Train Accuracy: 0.9482, Val Loss: 0.1475, Val Accuracy: 0.9542\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.1108, Train Accuracy: 0.9686, Val Loss: 0.1356, Val Accuracy: 0.9582\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.0741, Train Accuracy: 0.9871, Val Loss: 0.1293, Val Accuracy: 0.9701\n",
      "Epoch [8/50], Train Loss: 0.0726, Train Accuracy: 0.9846, Val Loss: 0.1319, Val Accuracy: 0.9602\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/50], Train Loss: 0.0713, Train Accuracy: 0.9831, Val Loss: 0.1139, Val Accuracy: 0.9701\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.0781, Train Accuracy: 0.9791, Val Loss: 0.0955, Val Accuracy: 0.9761\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.0457, Train Accuracy: 0.9930, Val Loss: 0.0873, Val Accuracy: 0.9801\n",
      "Epoch [12/50], Train Loss: 0.0526, Train Accuracy: 0.9890, Val Loss: 0.0896, Val Accuracy: 0.9741\n",
      "Epoch [13/50], Train Loss: 0.0489, Train Accuracy: 0.9890, Val Loss: 0.0923, Val Accuracy: 0.9761\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.0402, Train Accuracy: 0.9925, Val Loss: 0.0795, Val Accuracy: 0.9761\n",
      "Validation loss improved, saving model...\n",
      "Epoch [15/50], Train Loss: 0.0243, Train Accuracy: 0.9980, Val Loss: 0.0780, Val Accuracy: 0.9741\n",
      "Epoch [16/50], Train Loss: 0.0352, Train Accuracy: 0.9935, Val Loss: 0.0974, Val Accuracy: 0.9701\n",
      "Epoch [17/50], Train Loss: 0.0337, Train Accuracy: 0.9905, Val Loss: 0.1134, Val Accuracy: 0.9622\n",
      "Epoch [18/50], Train Loss: 0.0442, Train Accuracy: 0.9910, Val Loss: 0.1073, Val Accuracy: 0.9761\n",
      "Epoch [19/50], Train Loss: 0.0278, Train Accuracy: 0.9965, Val Loss: 0.1301, Val Accuracy: 0.9701\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_04.3.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 epoch -> 8m 59.7s  \n",
    "1 epoch -> 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_16664\\2772901171.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_04.3.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (bn1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_04.3.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0391, Test accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception모델 + BN층만 unfreeze 한 미세조정 결과:  \n",
    "- 1차 시도(데이터 증강(0.5) + 50epoch + dropout(0.5) + 초기 학습률(1e-5) + l2 규제(1e-4))  \n",
    ": Train(0.98 / 0.06), Val(0.96 / 0.13), Test(0.94 / 0.14)  \n",
    "\n",
    "- 2차 시도(데이터 증강(0.6) + 50epoch + dropout(0.5) + 초기 학습률(1e-5) + l2 규제(1e-4))  \n",
    ": Train()  \n",
    "\n",
    "- 3차 시도(데이터 증강(0.6) + 50epoch + dropout(0.5) + 초기 학습률(1e-5) + l2 규제(1e-4) + BN layer 추가)  \n",
    ": Train(0.99 / 0.02), Val(0.97 / 0.08), Test(0.99 / 0.04)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5차 fine tuning. 미세조정 전 오버샘플링을 통해 두 클래스의 비중을 맞춰서 데이터를 늘리고, 모델의 일반화를 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NG 이미지 수: 1178\n",
      "OK 이미지 수: 830\n",
      "오버샘플링 후 NG 이미지 수: 1178\n",
      "오버샘플링 후 OK 이미지 수: 1178\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image \n",
    "\n",
    "class OverSamplingDataset(Dataset):\n",
    "    def __init__(self, ng_dir, ok_dir, transform=None, aug=None):\n",
    "        self.ng_images = [os.path.join(ng_dir, img) for img in os.listdir(ng_dir)]\n",
    "        self.ok_images = [os.path.join(ok_dir, img) for img in os.listdir(ok_dir)]\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "\n",
    "        # NG 이미지 수와 OK 이미지 수 출력\n",
    "        print(f'NG 이미지 수: {len(self.ng_images)}')\n",
    "        print(f'OK 이미지 수: {len(self.ok_images)}')\n",
    "\n",
    "        # OK 이미지를 NG 이미지 수 만큼 반복하여 오버샘플링\n",
    "        self.ok_images = self.ok_images * (len(self.ng_images) // len(self.ok_images)) + self.ok_images[:len(self.ng_images) % len(self.ok_images)]\n",
    "\n",
    "        # 오버샘플링 후 OK 이미지 수가 830이 되도록 맞춤\n",
    "        self.ok_images = self.ok_images[:len(self.ng_images)]  # NG와 동일한 수로 제한\n",
    "\n",
    "        # 최종 데이터셋은 NG와 OK 이미지의 합\n",
    "        self.images = self.ng_images + self.ok_images\n",
    "        self.labels = [0] * len(self.ng_images) + [1] * len(self.ok_images)  # NG=0, OK=1\n",
    "\n",
    "        # 최종 이미지와 레이블 수 출력\n",
    "        print(f'오버샘플링 후 NG 이미지 수: {len(self.ng_images)}')\n",
    "        print(f'오버샘플링 후 OK 이미지 수: {len(self.ok_images)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # PIL 이미지로 열기\n",
    "\n",
    "        if self.aug is not None:\n",
    "            # PIL 이미지를 NumPy 배열로 변환\n",
    "            image = np.array(image)  # np.array로 변환\n",
    "            image = self.aug(image=image)['image']  # 데이터 증강 적용\n",
    "            image = Image.fromarray(image)  # 다시 PIL 이미지로 변환\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.6),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.6),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.6),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.6),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = OverSamplingDataset(ng_dir='../PCB_imgs/all/resize/train/NG/', ok_dir='../PCB_imgs/all/resize/train/OK/', transform=transform, aug=aug)\n",
    "validation_dataset = datasets.ImageFolder(root=val_dir, transform=transform)  # 검증, 테스트 데이터는 그대로 사용\n",
    "test_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.bn1 = nn.BatchNorm1d(50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n",
      "Layer: bn1.weight | Requires Grad: True\n",
      "Layer: bn1.bias | Requires Grad: True\n",
      "Layer: fc2.weight | Requires Grad: True\n",
      "Layer: fc2.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.6770, Train Accuracy: 0.5798, Val Loss: 0.5536, Val Accuracy: 0.7968\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.5617, Train Accuracy: 0.7063, Val Loss: 0.4659, Val Accuracy: 0.8267\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.4986, Train Accuracy: 0.7547, Val Loss: 0.4139, Val Accuracy: 0.8526\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.4429, Train Accuracy: 0.8005, Val Loss: 0.3812, Val Accuracy: 0.8506\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/50], Train Loss: 0.4007, Train Accuracy: 0.8281, Val Loss: 0.3422, Val Accuracy: 0.8606\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/50], Train Loss: 0.3568, Train Accuracy: 0.8612, Val Loss: 0.3199, Val Accuracy: 0.8785\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/50], Train Loss: 0.3191, Train Accuracy: 0.8782, Val Loss: 0.2919, Val Accuracy: 0.9004\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/50], Train Loss: 0.2977, Train Accuracy: 0.8956, Val Loss: 0.2786, Val Accuracy: 0.9024\n",
      "Validation loss improved, saving model...\n",
      "Epoch [9/50], Train Loss: 0.2625, Train Accuracy: 0.9104, Val Loss: 0.2631, Val Accuracy: 0.8984\n",
      "Validation loss improved, saving model...\n",
      "Epoch [10/50], Train Loss: 0.2441, Train Accuracy: 0.9249, Val Loss: 0.2598, Val Accuracy: 0.9084\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/50], Train Loss: 0.2184, Train Accuracy: 0.9380, Val Loss: 0.2420, Val Accuracy: 0.9084\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/50], Train Loss: 0.2053, Train Accuracy: 0.9461, Val Loss: 0.2253, Val Accuracy: 0.9183\n",
      "Validation loss improved, saving model...\n",
      "Epoch [13/50], Train Loss: 0.1933, Train Accuracy: 0.9499, Val Loss: 0.2188, Val Accuracy: 0.9243\n",
      "Validation loss improved, saving model...\n",
      "Epoch [14/50], Train Loss: 0.1785, Train Accuracy: 0.9576, Val Loss: 0.2082, Val Accuracy: 0.9323\n",
      "Epoch [15/50], Train Loss: 0.1584, Train Accuracy: 0.9673, Val Loss: 0.2096, Val Accuracy: 0.9303\n",
      "Validation loss improved, saving model...\n",
      "Epoch [16/50], Train Loss: 0.1468, Train Accuracy: 0.9750, Val Loss: 0.1863, Val Accuracy: 0.9382\n",
      "Epoch [17/50], Train Loss: 0.1501, Train Accuracy: 0.9677, Val Loss: 0.1913, Val Accuracy: 0.9422\n",
      "Validation loss improved, saving model...\n",
      "Epoch [18/50], Train Loss: 0.1364, Train Accuracy: 0.9754, Val Loss: 0.1843, Val Accuracy: 0.9422\n",
      "Validation loss improved, saving model...\n",
      "Epoch [19/50], Train Loss: 0.1183, Train Accuracy: 0.9817, Val Loss: 0.1790, Val Accuracy: 0.9442\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/50], Train Loss: 0.1263, Train Accuracy: 0.9775, Val Loss: 0.1745, Val Accuracy: 0.9462\n",
      "Validation loss improved, saving model...\n",
      "Epoch [21/50], Train Loss: 0.1160, Train Accuracy: 0.9813, Val Loss: 0.1715, Val Accuracy: 0.9382\n",
      "Validation loss improved, saving model...\n",
      "Epoch [22/50], Train Loss: 0.1111, Train Accuracy: 0.9830, Val Loss: 0.1710, Val Accuracy: 0.9422\n",
      "Validation loss improved, saving model...\n",
      "Epoch [23/50], Train Loss: 0.1095, Train Accuracy: 0.9830, Val Loss: 0.1666, Val Accuracy: 0.9542\n",
      "Epoch [24/50], Train Loss: 0.0999, Train Accuracy: 0.9894, Val Loss: 0.1734, Val Accuracy: 0.9402\n",
      "Validation loss improved, saving model...\n",
      "Epoch [25/50], Train Loss: 0.0994, Train Accuracy: 0.9847, Val Loss: 0.1577, Val Accuracy: 0.9522\n",
      "Validation loss improved, saving model...\n",
      "Epoch [26/50], Train Loss: 0.0906, Train Accuracy: 0.9919, Val Loss: 0.1558, Val Accuracy: 0.9502\n",
      "Epoch [27/50], Train Loss: 0.0892, Train Accuracy: 0.9877, Val Loss: 0.1621, Val Accuracy: 0.9482\n",
      "Validation loss improved, saving model...\n",
      "Epoch [28/50], Train Loss: 0.0787, Train Accuracy: 0.9915, Val Loss: 0.1518, Val Accuracy: 0.9542\n",
      "Validation loss improved, saving model...\n",
      "Epoch [29/50], Train Loss: 0.0805, Train Accuracy: 0.9911, Val Loss: 0.1480, Val Accuracy: 0.9502\n",
      "Validation loss improved, saving model...\n",
      "Epoch [30/50], Train Loss: 0.0773, Train Accuracy: 0.9928, Val Loss: 0.1476, Val Accuracy: 0.9542\n",
      "Validation loss improved, saving model...\n",
      "Epoch [31/50], Train Loss: 0.0691, Train Accuracy: 0.9958, Val Loss: 0.1444, Val Accuracy: 0.9602\n",
      "Validation loss improved, saving model...\n",
      "Epoch [32/50], Train Loss: 0.0709, Train Accuracy: 0.9928, Val Loss: 0.1437, Val Accuracy: 0.9602\n",
      "Validation loss improved, saving model...\n",
      "Epoch [33/50], Train Loss: 0.0727, Train Accuracy: 0.9936, Val Loss: 0.1430, Val Accuracy: 0.9522\n",
      "Epoch [34/50], Train Loss: 0.0658, Train Accuracy: 0.9945, Val Loss: 0.1468, Val Accuracy: 0.9582\n",
      "Validation loss improved, saving model...\n",
      "Epoch [35/50], Train Loss: 0.0685, Train Accuracy: 0.9941, Val Loss: 0.1337, Val Accuracy: 0.9602\n",
      "Epoch [36/50], Train Loss: 0.0646, Train Accuracy: 0.9958, Val Loss: 0.1339, Val Accuracy: 0.9582\n",
      "Epoch [37/50], Train Loss: 0.0617, Train Accuracy: 0.9966, Val Loss: 0.1371, Val Accuracy: 0.9602\n",
      "Epoch [38/50], Train Loss: 0.0625, Train Accuracy: 0.9932, Val Loss: 0.1377, Val Accuracy: 0.9542\n",
      "Epoch [39/50], Train Loss: 0.0634, Train Accuracy: 0.9919, Val Loss: 0.1339, Val Accuracy: 0.9622\n",
      "Validation loss improved, saving model...\n",
      "Epoch [40/50], Train Loss: 0.0549, Train Accuracy: 0.9966, Val Loss: 0.1323, Val Accuracy: 0.9641\n",
      "Epoch [41/50], Train Loss: 0.0531, Train Accuracy: 0.9970, Val Loss: 0.1368, Val Accuracy: 0.9622\n",
      "Validation loss improved, saving model...\n",
      "Epoch [42/50], Train Loss: 0.0524, Train Accuracy: 0.9975, Val Loss: 0.1301, Val Accuracy: 0.9582\n",
      "Epoch [43/50], Train Loss: 0.0509, Train Accuracy: 0.9970, Val Loss: 0.1313, Val Accuracy: 0.9582\n",
      "Epoch [44/50], Train Loss: 0.0493, Train Accuracy: 0.9970, Val Loss: 0.1309, Val Accuracy: 0.9602\n",
      "Validation loss improved, saving model...\n",
      "Epoch [45/50], Train Loss: 0.0526, Train Accuracy: 0.9958, Val Loss: 0.1284, Val Accuracy: 0.9661\n",
      "Validation loss improved, saving model...\n",
      "Epoch [46/50], Train Loss: 0.0572, Train Accuracy: 0.9945, Val Loss: 0.1245, Val Accuracy: 0.9681\n",
      "Epoch [47/50], Train Loss: 0.0462, Train Accuracy: 0.9983, Val Loss: 0.1264, Val Accuracy: 0.9582\n",
      "Epoch [48/50], Train Loss: 0.0504, Train Accuracy: 0.9979, Val Loss: 0.1256, Val Accuracy: 0.9681\n",
      "Validation loss improved, saving model...\n",
      "Epoch [49/50], Train Loss: 0.0497, Train Accuracy: 0.9958, Val Loss: 0.1223, Val Accuracy: 0.9641\n",
      "Epoch [50/50], Train Loss: 0.0474, Train Accuracy: 0.9979, Val Loss: 0.1285, Val Accuracy: 0.9681\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_05.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 epoch -> 28m 10.0s  \n",
    "1 epoch -> s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enssel\\AppData\\Local\\Temp\\ipykernel_16664\\2029228131.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../model/inception_ft_best_model_05.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=50, bias=True)\n",
       "  (bn1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 클래스 정의 (CustomModel)\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 저장된 체크포인트 불러오기\n",
    "checkpoint = torch.load('../model/inception_ft_best_model_05.pth')\n",
    "\n",
    "# 모델에 체크포인트 적용\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 에포크 정보 가져오기 (옵션)\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1223, Test accuracy: 0.9641\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오버샘플링 후 fine tuning 진행한 결과:  \n",
    "Train ( / )  \n",
    "Val ( / )  \n",
    "Test ( / )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 1)\n",
    "        # self.bn1 = nn.BatchNorm1d(50)\n",
    "        # self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        # x = self.bn1(x)\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.Conv2d_1a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_1a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_2b_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_3b_1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Conv2d_4a_3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch5x5_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_5d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6a.branch3x3dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6d.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch7x7dbl_5.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_6e.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv0.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv0.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.conv1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.conv1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.AuxLogits.fc.weight | Requires Grad: True\n",
      "Layer: base_model.AuxLogits.fc.bias | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch3x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_3.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7a.branch7x7x3_4.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7b.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch1x1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3_2b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_1.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_2.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3a.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch3x3dbl_3b.bn.bias | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.conv.weight | Requires Grad: True\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.weight | Requires Grad: False\n",
      "Layer: base_model.Mixed_7c.branch_pool.bn.bias | Requires Grad: False\n",
      "Layer: fc1.weight | Requires Grad: True\n",
      "Layer: fc1.bias | Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-3)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, saving model...\n",
      "Epoch [1/50], Train Loss: 0.6337, Train Accuracy: 0.6261, Val Loss: 0.5457, Val Accuracy: 0.7729\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/50], Train Loss: 0.5063, Train Accuracy: 0.7649, Val Loss: 0.4291, Val Accuracy: 0.8347\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/50], Train Loss: 0.4309, Train Accuracy: 0.8039, Val Loss: 0.3686, Val Accuracy: 0.8486\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/50], Train Loss: 0.3721, Train Accuracy: 0.8391, Val Loss: 0.3237, Val Accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_05.1.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image \n",
    "\n",
    "class OverSamplingDataset(Dataset):\n",
    "    def __init__(self, ng_dir, ok_dir, transform=None, aug=None):\n",
    "        self.ng_images = [os.path.join(ng_dir, img) for img in os.listdir(ng_dir)]\n",
    "        self.ok_images = [os.path.join(ok_dir, img) for img in os.listdir(ok_dir)]\n",
    "        self.transform = transform\n",
    "        self.aug = aug\n",
    "\n",
    "        # NG 이미지 수와 OK 이미지 수 출력\n",
    "        print(f'NG 이미지 수: {len(self.ng_images)}')\n",
    "        print(f'OK 이미지 수: {len(self.ok_images)}')\n",
    "\n",
    "        # OK 이미지를 NG 이미지 수 만큼 반복하여 오버샘플링\n",
    "        self.ok_images = self.ok_images * (len(self.ng_images) // len(self.ok_images)) + self.ok_images[:len(self.ng_images) % len(self.ok_images)]\n",
    "\n",
    "        # 오버샘플링 후 OK 이미지 수가 830이 되도록 맞춤\n",
    "        self.ok_images = self.ok_images[:len(self.ng_images)]  # NG와 동일한 수로 제한\n",
    "\n",
    "        # 최종 데이터셋은 NG와 OK 이미지의 합\n",
    "        self.images = self.ng_images + self.ok_images\n",
    "        self.labels = [0] * len(self.ng_images) + [1] * len(self.ok_images)  # NG=0, OK=1\n",
    "\n",
    "        # 최종 이미지와 레이블 수 출력\n",
    "        print(f'오버샘플링 후 NG 이미지 수: {len(self.ng_images)}')\n",
    "        print(f'오버샘플링 후 OK 이미지 수: {len(self.ok_images)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # PIL 이미지로 열기\n",
    "\n",
    "        if self.aug is not None:\n",
    "            # PIL 이미지를 NumPy 배열로 변환\n",
    "            image = np.array(image)  # np.array로 변환\n",
    "            image = self.aug(image=image)['image']  # 데이터 증강 적용\n",
    "            image = Image.fromarray(image)  # 다시 PIL 이미지로 변환\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 데이터 증강 정의\n",
    "aug = A.Compose([\n",
    "    A.HorizontalFlip(p=0.6),                # 좌우 반전\n",
    "    A.VerticalFlip(p=0.6),                  # 상하 반전\n",
    "    A.Rotate(limit=10, p=0.6),              # 작은 각도 회전 (10도 내외)\n",
    "    A.RandomBrightnessContrast(p=0.6),      # 밝기 및 대비 조절\n",
    "])\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "train_dataset = OverSamplingDataset(ng_dir='../PCB_imgs/all/resize/train/NG/', ok_dir='../PCB_imgs/all/resize/train/OK/', transform=transform, aug=aug)\n",
    "validation_dataset = datasets.ImageFolder(root=val_dir, transform=transform)  # 검증, 테스트 데이터는 그대로 사용\n",
    "test_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name='vgg16'):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_name == 'vgg16':\n",
    "            self.base_model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'resnet50':\n",
    "            self.base_model = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "            self.base_model = nn.Sequential(*list(self.base_model.children())[:-1])  # 마지막 레이어 제거\n",
    "        elif model_name == 'inception':\n",
    "            self.base_model = torchvision.models.inception_v3(weights='IMAGENET1K_V1')\n",
    "            self.base_model.fc = nn.Identity()  # 마지막 분류기 제거\n",
    "        elif model_name == 'mobilenet':\n",
    "            self.base_model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "            self.base_model.classifier = nn.Identity()  # 마지막 분류기 제거\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(self._get_features_dim(model_name), 50)\n",
    "        self.bn1 = nn.BatchNorm1d(50)\n",
    "        self.fc2 = nn.Linear(50, 1)  # Sigmoid 출력\n",
    "\n",
    "    def _get_features_dim(self, model_name):\n",
    "        if model_name == 'vgg16':\n",
    "            return 25088  # VGG16의 출력 차원\n",
    "        elif model_name in ['resnet50', 'inception']:\n",
    "            return 2048  # ResNet50 및 Inception의 출력 차원\n",
    "        elif model_name == 'mobilenet':\n",
    "            return 1280  # MobileNetV2의 출력 차원\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Inception 모델에 대한 수정\n",
    "        if isinstance(x, tuple):  # Inception 모델이 여러 출력을 반환하는 경우\n",
    "            x = x[0]  # 첫 번째 출력을 선택\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = CustomModel(model_name='inception').to(DEVICE)\n",
    "\n",
    "# 1. 사전 학습된 base_model의 파라미터를 동결 (fine-tuning 초기 단계)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. BatchNorm 층만 동결, 나머지는 동결 해제\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"bn\" in name.lower(): \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True  \n",
    "\n",
    "# 동결 해제된 일부 층과 분류기 층 학습\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "# 학습할 손실 함수\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 각 층의 freeze/unfreeze 상태 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "# 조기 종료 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # 개선이 없을 때 기다릴 에포크 수\n",
    "patience_counter = 0\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(DEVICE), targets.to(DEVICE).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs.view(-1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs.view(-1)) > 0.5).float()\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        total_predictions += targets.size(0)\n",
    "\n",
    "    # 훈련 데이터 정확도\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # 검증\n",
    "    val_loss, val_accuracy = evaluate_model(model, validation_loader, criterion)\n",
    "\n",
    "    # 학습률 스케줄러 적용\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 조기 종료 로직\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # 손실 개선 시 카운터 리셋\n",
    "        print(\"Validation loss improved, saving model...\")  \n",
    "        # 모델 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, '../model/inception_ft_best_model_05.2.pth')\n",
    "    else:\n",
    "        patience_counter += 1  # 손실이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break  # 훈련 종료\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
